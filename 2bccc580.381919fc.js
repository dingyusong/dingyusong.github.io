(window.webpackJsonp=window.webpackJsonp||[]).push([[55],{127:function(e,t,o){"use strict";o.r(t),o.d(t,"frontMatter",(function(){return s})),o.d(t,"metadata",(function(){return u})),o.d(t,"toc",(function(){return p})),o.d(t,"default",(function(){return d}));var i=o(3),n=o(7),a=(o(0),o(356)),r=["components"],s={},u={unversionedId:"\u97f3\u89c6\u9891/\u5b66\u4e60\u8d44\u6599/\u6559\u7a0b/Audio-Session-Programming-Guide",id:"\u97f3\u89c6\u9891/\u5b66\u4e60\u8d44\u6599/\u6559\u7a0b/Audio-Session-Programming-Guide",isDocsHomePage:!1,title:"Audio-Session-Programming-Guide",description:"Audio Session Programming Guide",source:"@site/docs/\u97f3\u89c6\u9891/\u5b66\u4e60\u8d44\u6599/\u6559\u7a0b/Audio-Session-Programming-Guide.md",slug:"/\u97f3\u89c6\u9891/\u5b66\u4e60\u8d44\u6599/\u6559\u7a0b/Audio-Session-Programming-Guide",permalink:"/docs/\u97f3\u89c6\u9891/\u5b66\u4e60\u8d44\u6599/\u6559\u7a0b/Audio-Session-Programming-Guide",editUrl:"dys-typora-open://mine/survival/docs/\u97f3\u89c6\u9891/\u5b66\u4e60\u8d44\u6599/\u6559\u7a0b/Audio-Session-Programming-Guide.md",version:"current"},p=[{value:"Configuring  an Audio Session",id:"configuring--an-audio-session",children:[{value:"Audio Session Default Behavior",id:"audio-session-default-behavior",children:[]},{value:"Configuring Your Audio Session",id:"configuring-your-audio-session",children:[]},{value:"Expanding Options Using the Multiroute Category",id:"expanding-options-using-the-multiroute-category",children:[]},{value:"Chooseing Categores and Modes for Airplay",id:"chooseing-categores-and-modes-for-airplay",children:[]},{value:"Enabling background Audio",id:"enabling-background-audio",children:[]}]},{value:"Activating an Audio Session",id:"activating-an-audio-session",children:[{value:"How the System Resolves Competing Audio Demands",id:"how-the-system-resolves-competing-audio-demands",children:[]},{value:"Activity and Deactivaty you Audio Session",id:"activity-and-deactivaty-you-audio-session",children:[]},{value:"Checking Whether Other Audio is Playing",id:"checking-whether-other-audio-is-playing",children:[]}]},{value:"Responding to interruptions",id:"responding-to-interruptions",children:[{value:"The Interruption Life Cycle",id:"the-interruption-life-cycle",children:[]},{value:"Audio Interruption handling Techniques",id:"audio-interruption-handling-techniques",children:[]},{value:"Handling Interruption from Siri",id:"handling-interruption-from-siri",children:[]},{value:"Observer Audio Interruptions",id:"observer-audio-interruptions",children:[]},{value:"Responding  to a media server Reset",id:"responding--to-a-media-server-reset",children:[]}]},{value:"Responding to Route Changes",id:"responding-to-route-changes",children:[{value:"Varieties Of Audio Hardware Route Change",id:"varieties-of-audio-hardware-route-change",children:[]},{value:"Observering Audio Route Changes",id:"observering-audio-route-changes",children:[]}]},{value:"Configuring Device Hardware",id:"configuring-device-hardware",children:[{value:"Choosing Preferred Audio Hardware Values",id:"choosing-preferred-audio-hardware-values",children:[]},{value:"Setting Preferred Audio Hardware Values",id:"setting-preferred-audio-hardware-values",children:[]},{value:"Selecting And Configuring Microphones",id:"selecting-and-configuring-microphones",children:[]},{value:"Runing your app in simulator",id:"runing-your-app-in-simulator",children:[]}]},{value:"Protecting User Privacy",id:"protecting-user-privacy",children:[{value:"Requesting Permission to Record Audio",id:"requesting-permission-to-record-audio",children:[]}]},{value:"Appendix A: Audio Guideline By App Type",id:"appendix-a-audio-guideline-by-app-type",children:[{value:"Audio Guidelines for Game Apps",id:"audio-guidelines-for-game-apps",children:[]},{value:"Audio Guidelines for User-Controlled Playback and Recording Apps",id:"audio-guidelines-for-user-controlled-playback-and-recording-apps",children:[]},{value:"Audio Guidelines for VoIP and Chat Apps",id:"audio-guidelines-for-voip-and-chat-apps",children:[]},{value:"Audio Guidelines for Metering Apps",id:"audio-guidelines-for-metering-apps",children:[]},{value:"Audio Guidelines for Browser-like Apps That Sometimes Play Audio",id:"audio-guidelines-for-browser-like-apps-that-sometimes-play-audio",children:[]},{value:"Audio Guidelines for Navigation and Workout Apps",id:"audio-guidelines-for-navigation-and-workout-apps",children:[]},{value:"Audio Guidelines for Cooperative Music Apps",id:"audio-guidelines-for-cooperative-music-apps",children:[]}]},{value:"Appendix B: Audio Session Categories and Modes",id:"appendix-b-audio-session-categories-and-modes",children:[]},{value:"Reference",id:"reference",children:[]}],c={toc:p};function d(e){var t=e.components,s=Object(n.a)(e,r);return Object(a.b)("wrapper",Object(i.a)({},c,s,{components:t,mdxType:"MDXLayout"}),Object(a.b)("h1",{id:"audio-session-programming-guide"},"Audio Session Programming Guide"),Object(a.b)("p",null,"[toc]"),Object(a.b)("p",null,"Audio is a managed service in iOS, tvOS, and watchOS. The system manages audio behavior at the app, inter-app, and device levels through the use of ",Object(a.b)("em",{parentName:"p"},"audio sessions"),"."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"managed service \u6258\u7ba1\u670d\u52a1"),Object(a.b)("p",{parentName:"blockquote"},"through the use of ",Object(a.b)("em",{parentName:"p"},"audio sessions"),". \u901a\u8fc7\u4f7f\u7528 audio session")),Object(a.b)("p",null,Object(a.b)("img",{alt:"../Art/ASPG_intro_2x.png",src:o(487).default})),Object(a.b)("p",null,"You use an audio session to communicate to the system how you intend to use audio in your app. This audio session acts as an intermediary between your app and the operating system\u2014and in turn, the underlying audio hardware. You use it to communicate to the operating system the nature of your app\u2019s audio without detailing the specific behavior or required interactions with the audio hardware. Delegating the management of those details to the audio session ensures optimal management of the user\u2019s audio experience."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"the nature of your app\u2019s audio  \u5e94\u7528\u7a0b\u5e8f\u97f3\u9891\u7684\u6027\u8d28"),Object(a.b)("p",{parentName:"blockquote"},"optimal management of the user\u2019s audio experience. \u7528\u6237\u7684\u97f3\u9891\u4f53\u9a8c\u5230\u7684\u6700\u4f73\u7ba1\u7406")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"At a Glance")),Object(a.b)("p",null,"You interact with your app\u2019s audio session using an instance of ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSession")," to:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Configure the audio session category and mode to communicate to the system how you intend to use audio in your app"),Object(a.b)("li",{parentName:"ul"},"Activate your app\u2019s audio session to put your category and mode configuration into action"),Object(a.b)("li",{parentName:"ul"},"Subscribe and respond to important audio session notifications, such as audio interruptions and route changes"),Object(a.b)("li",{parentName:"ul"},"Perform advanced audio device configuration such as setting sample rate, I/O buffer duration, and number of channels")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"An Audio Session Manages Audio Behavior")),Object(a.b)("p",null,"An ",Object(a.b)("em",{parentName:"p"},"audio session")," is the intermediary between your app and the operating system that is used to configure your app\u2019s audio behavior. Upon launch, your app is automatically provided with a singleton audio session. You configure it to provide the desired behavior and activate it to put that behavior into action."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},Object(a.b)("strong",{parentName:"p"},"Relevant Chapters:")," ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/ConfiguringanAudioSession/ConfiguringanAudioSession.html#//apple_ref/doc/uid/TP40007875-CH2-SW1"},"Activating an Audio Session"),".")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Categories Express Audio Roles")),Object(a.b)("p",null,"The primary mechanism for expressing audio behaviors is the audio session category. By setting the category, you indicate whether your app uses input or output routes, whether you want music to continue playing along with your audio, and so on. The behavior you specify should meet user expectations as described in ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/ios/human-interface-guidelines/interaction/audio/"},"Audio")," in ",Object(a.b)("em",{parentName:"p"},"iOS Human Interface Guidelines"),"."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"expressing audio behaviors \u8868\u8fbe\u97f3\u9891\u884c\u4e3a"),Object(a.b)("p",{parentName:"blockquote"},"The primary mechanism\uff1a \u4e3b\u8981\u673a\u5236")),Object(a.b)("p",null,"AVFoundation defines a number of audio session categories, along with a set of override and modifier switches, that let you customize audio behavior according to your app\u2019s personality or role."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"along with \u4ee5\u53ca"),Object(a.b)("p",{parentName:"blockquote"}," a set of override and modifier switches \u4e00\u7ec4\u66ff\u4ee3\u548c\u4fee\u9970\u7b26\u5f00\u5173"),Object(a.b)("p",{parentName:"blockquote"}," customize audio behavior \u81ea\u5b9a\u4e49\u97f3\u9891\u884c\u4e3a")),Object(a.b)("p",null,"Various categories support playback, recording, and playback with recording. When the system knows your app\u2019s audio role, it provides you appropriate access to hardware resources. The system also ensures that other audio on the device behaves in a way that works for your app and is consistent with user expectations."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"}," is consistent with \u7b26\u5408")),Object(a.b)("p",null,"Some categories can further be customized by specifying a mode, which is used to specialize the behavior of a given category. For example, when an app uses Video Recording mode, the system might choose a different built-in microphone than it would choose if it were using the default mode. The system might also engage microphone signal processing that is tuned for video recording use cases."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"engage microphone signal processing   \u8c03\u6574 microphone signal processing "),Object(a.b)("p",{parentName:"blockquote"}," tuned for video recording use cases. \u9488\u5bf9\u5f55\u50cf\u7528\u4f8b\u8fdb\u884c\u8c03\u6574")),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},Object(a.b)("strong",{parentName:"p"},"Relevant Chapters:")," ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionBasics/AudioSessionBasics.html#//apple_ref/doc/uid/TP40007875-CH3-SW1"},"Configuring an Audio Session"),".")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Notifications Support Interruption Handling")),Object(a.b)("p",null,"An ",Object(a.b)("em",{parentName:"p"},"audio interruption")," is the deactivation of your app\u2019s audio session\u2014which immediately stops your audio. Interruptions occur when a competing audio session from an app is activated and that session is not categorized by the system to mix with yours. Your app should respond to interruptions by saving state, updating the user interface, and so on. To be notified when audio interruptions begin and end, register to observe notifications of type ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionInterruptionNotification"),"."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"}," categorized by the system to mix with yours. \u7cfb\u7edf\u5f52\u7c7b\u4e8e\u60a8\u7684\u4f1a\u8bdd\u6df7\u5408")),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},Object(a.b)("strong",{parentName:"p"},"Relevant Chapters:")," ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/HandlingAudioInterruptions/HandlingAudioInterruptions.html#//apple_ref/doc/uid/TP40007875-CH4-SW1"},"Responding to Interruptions"),".")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"otifications Support Audio Route Change Handling")),Object(a.b)("p",null,"Users have particular expectations when they initiate an ",Object(a.b)("em",{parentName:"p"},"audio route change")," by docking or undocking a device, or by plugging in or unplugging a headset. ",Object(a.b)("em",{parentName:"p"},"iOS Human Interface Guidelines")," describes these expectations and provides guidelines on how to meet them. Handle route changes by registering to observe notifications of type ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteChangeNotification"),"."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"particular expectations \u7279\u522b\u7684\u671f\u5f85 "),Object(a.b)("p",{parentName:"blockquote"},"docking \u7801\u5934\uff0c\u9760\u5cb8\uff0c\u5bf9\u63a5"),Object(a.b)("p",{parentName:"blockquote"},"undocking \u79bb\u5f00\u7801\u5934\uff0c\u65ad\u5f00\u8fde\u63a5")),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},Object(a.b)("strong",{parentName:"p"},"Relevant Chapters:")," ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/HandlingAudioHardwareRouteChanges/HandlingAudioHardwareRouteChanges.html#//apple_ref/doc/uid/TP40007875-CH5-SW1"},"Responding to Route Changes"),".")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Audio Sessions Control Device Configuration")),Object(a.b)("p",null,"Apps don\u2019t have direct control over device hardware, but an audio session provides the interface for you to request your ",Object(a.b)("em",{parentName:"p"},"preferred")," hardware device settings. This interface enables you to perform advanced audio device configuration such as setting sample rate, I/O buffer duration, and number of audio channels."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},Object(a.b)("strong",{parentName:"p"},"Relevant Chapters:")," ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/OptimizingForDeviceHardware/OptimizingForDeviceHardware.html#//apple_ref/doc/uid/TP40007875-CH6-SW1"},"Configuring Device Hardware"),".")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Audio Sessions Protect User Privacy")),Object(a.b)("p",null,"Apps that record audio, alone or in conjunction with video, require explicit user permission before recording is allowed. Until the user grants your app permission to record, the app can record only silence. ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSession")," provides the interface to ask for this permission and determine the user\u2019s privacy setting."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"determine \uff1a \u51b3\u5b9a\uff0c\u786e\u5b9a "),Object(a.b)("p",{parentName:"blockquote"},"determine the user\u2019s privacy setting. \u786e\u5b9a\u7528\u6237\u7684\u9690\u79c1\u8bbe\u7f6e")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Prerequisites")),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"\u9884\u5907\u77e5\u8bc6")),Object(a.b)("p",null,"Be familiar with Cocoa Touch development as introduced in ",Object(a.b)("em",{parentName:"p"},Object(a.b)("a",{parentName:"em",href:"https://developer.apple.com/library/archive/documentation/iPhone/Conceptual/iPhoneOSProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40007072"},"App Programming Guide for iOS"))," and with the basics of Core Audio as described in that document and in ",Object(a.b)("em",{parentName:"p"},Object(a.b)("a",{parentName:"em",href:"https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/Introduction/Introduction.html#//apple_ref/doc/uid/TP40003577"},"Core Audio Overview")),". Because audio sessions bear on practical end-user scenarios, also be familiar with iOS devices and with iOS Human Interface Guidelines, especially the ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/ios/human-interface-guidelines/interaction/audio/"},"Audio")," section in ",Object(a.b)("em",{parentName:"p"},"iOS Human Interface Guidelines"),"."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"especially the Audio section in iOS Human Interface Guidelines. \u7279\u522b\u662f\u4eba\u9645\u4ea4\u4e92\u6307\u5357\u7684\u97f3\u9891\u90e8\u5206")),Object(a.b)("p",null,Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/design/human-interface-guidelines/ios/user-interaction/audio/"},"https://developer.apple.com/design/human-interface-guidelines/ios/user-interaction/audio/")),Object(a.b)("h2",{id:"configuring--an-audio-session"},"Configuring  an Audio Session"),Object(a.b)("p",null,"An audio session category is a key that identifies a set of audio behaviors for your app. By setting a category, you indicate your audio intentions to the system\u2014such as whether your audio should continue when the Ringer/Silent switch is flipped. Several audio session categories, along with a set of override and modifier switches, let you customize your app\u2019s audio behavior."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"when the Ringer/Silent switch is flipped. \u5f53\u632f\u94c3/\u9759\u97f3\u5f00\u5173\u88ab\u62e8\u52a8\u7684\u65f6\u5019"),Object(a.b)("p",{parentName:"blockquote"},"Several audio session categories \u591a\u4e2a\u97f3\u9891\u4f1a\u8bdd\u7c7b\u522b"),Object(a.b)("p",{parentName:"blockquote"}," along with \u4ee5\u53ca"),Object(a.b)("p",{parentName:"blockquote"},"override and modifier switches \u66ff\u4ee3\u548c\u4fee\u9970\u7b26\u5f00\u5173"),Object(a.b)("p",{parentName:"blockquote"},"customize your app\u2019s audio behavior. \u81ea\u5b9a\u4e49\u97f3\u9891\u7684\u884c\u4e3a")),Object(a.b)("p",null,"As detailed in ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionCategoriesandModes/AudioSessionCategoriesandModes.html#//apple_ref/doc/uid/TP40007875-CH10-SW3"},"Table B-1"),", each audio session category specifies a particular set of responses to each of the following behaviors:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},Object(a.b)("em",{parentName:"li"},"Interrupts nonmixable apps audio:")," If yes, nonmixable apps are interrupted when your app activates its audio session."),Object(a.b)("li",{parentName:"ul"},Object(a.b)("em",{parentName:"li"},"Silenced by the Silent switch:")," If yes, your audio is silenced when the user activates the Silent switch. (On iPhone, this switch is called the ",Object(a.b)("em",{parentName:"li"},"Ring/Silent switch"),".)"),Object(a.b)("li",{parentName:"ul"},Object(a.b)("em",{parentName:"li"},"Supports audio input:")," If yes, app audio input (recording) is allowed."),Object(a.b)("li",{parentName:"ul"},Object(a.b)("em",{parentName:"li"},"Supports audio output:")," If yes, app audio output (playback) is allowed.")),Object(a.b)("p",null,"Most apps only need to set the category once, at launch, but you can change the category as often as you need to. You can change it while the audio session is active; however, it\u2019s generally preferable to deactivate your audio session before changing the category or other session properties. Making these changes while the session is deactivated prevents unnecessary reconfigurations of the audio system."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"it\u2019s generally preferable to \u901a\u5e38\u6700\u597d"),Object(a.b)("p",{parentName:"blockquote"},"deactivate your audio session \u505c\u7528\u4f60\u7684audio session")),Object(a.b)("h3",{id:"audio-session-default-behavior"},"Audio Session Default Behavior"),Object(a.b)("p",null,"All iOS, tvOS, and watchOS apps have a default audio session that is preconfigured as follows:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Audio playback is supported, but audio recording is disallowed."),Object(a.b)("li",{parentName:"ul"},"In iOS, setting the Ring/Silent switch to silent mode silences any audio being played by the app."),Object(a.b)("li",{parentName:"ul"},"In iOS, when the device is locked, the app's audio is silenced."),Object(a.b)("li",{parentName:"ul"},"When your app plays audio, any other background audio\u2014such as audio being played by the Music app\u2014is silenced.")),Object(a.b)("p",null,"The default audio session has useful behavior, but in most cases, you should customize it to better suit your app\u2019s needs. To change the behavior, you configure your app\u2019s audio session."),Object(a.b)("h3",{id:"configuring-your-audio-session"},"Configuring Your Audio Session"),Object(a.b)("p",null,"The primary means of configuring your audio session is by setting its category. An audio session category defines a set of audio behaviors. The precise behaviors associated with each category are not under your app\u2019s control, but rather are set by the operating system. Apple may refine category behavior in future versions of the OS, so your best strategy is to pick the category that most accurately describes your intentions for the audio behavior you want. ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionCategoriesandModes/AudioSessionCategoriesandModes.html#//apple_ref/doc/uid/TP40007875-CH10-SW1"},"Audio Session Categories and Modes")," summarizes behavior details for each category."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"}," most accurately describes \u6700\u7cbe\u51c6\u7684\u63cf\u8ff0")),Object(a.b)("p",null,"While categories set the base audio behaviors for your app, you can further specialize those behaviors by setting the category\u2019s mode. For instance, a Voice over IP (VoIP) app would use ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionCategoryPlayAndRecord"),". You can specialize the behavior of this category for a VoIP app by setting the audio session\u2019s mode to ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionModeVoiceChat"),". This mode ensures that signals are optimized for voice through system-supplied signal processing."),Object(a.b)("p",null,"Certain categories support overriding their default behavior by setting one or more category options on the session (see ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionCategoryOptions"),"). For instance, the default behavior associated with the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionCategoryPlayback")," category interrupts other system audio when the session is activated. In most cases, a playback app needs this behavior. However, if you want your audio to mix with other system audio, you can override this behavior by setting the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionCategoryOptionMixWithOthers")," option on the session."),Object(a.b)("p",null,"To set the audio session category (and optionally its mode and options), call the ",Object(a.b)("inlineCode",{parentName:"p"},"setCategory:mode:options:error:")," method as shown in Listing 1-1."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Listing 1-1")," Setting the audio session category using the AVFoundation framework"),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-c"},'// Access the shared, singleton audio session instance\nlet session = AVAudioSession.sharedInstance()\ndo {\n    // Configure the audio session for movie playback\n    try session.setCategory(AVAudioSessionCategoryPlayback,\n                            mode: AVAudioSessionModeMoviePlayback,\n                            options: [])\n} catch let error as NSError {\n    print("Failed to set the audio session category and mode: \\(error.localizedDescription)")\n}\n')),Object(a.b)("h3",{id:"expanding-options-using-the-multiroute-category"},"Expanding Options Using the Multiroute Category"),Object(a.b)("p",null,"The multiroute category works slightly differently from the other categories. All other categories follow the \u201clast in wins\u201d rule, where the last device plugged into an input or output route is the dominant device. However, the multiroute category enables the app to use all of the connected output ports instead of only the last-in port. For example, if you are listening to audio through the HDMI output route and plug in a set of headphones, your app continues playing audio through the HDMI output route while also playing audio through the headphones."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"slightly differently from \u7a0d\u5fae\u4e0d\u540c")),Object(a.b)("p",null,"With the multiroute category, your app can also send different audio streams to different output routes. For example, your app can send one audio stream to the left headphone, another to the right headphone, and a third to the HDMI routes. Figure 1-1 shows an example of sending multiple audio streams to different audio routes."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Figure 1-1")," Sending different audio streams to different audio routes"),Object(a.b)("p",null,Object(a.b)("img",{alt:"img",src:o(488).default})),Object(a.b)("p",null,"Depending on the device and any connected accessories, the following are valid output route combinations:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"USB and headphones"),Object(a.b)("li",{parentName:"ul"},"HDMI and headphones"),Object(a.b)("li",{parentName:"ul"},"LineOut and headphones")),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"Depending on \u6839\u636e"),Object(a.b)("p",{parentName:"blockquote"},"valid output route combinations \uff1a\u6709\u6548\u7684\u8f93\u51fa\u8def\u7531\u7ec4\u5408")),Object(a.b)("p",null,"The multiroute category supports the use of a single input port."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Important:")," The built-in speaker may be used only if no other eligible output ports (USB, HDMI, LineOut) are connected."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"no other eligible output ports \u6ca1\u6709\u5176\u4ed6\u5408\u9002\u7684\u8f93\u51fa\u7aef\u53e3")),Object(a.b)("h3",{id:"chooseing-categores-and-modes-for-airplay"},"Chooseing Categores and Modes for Airplay"),Object(a.b)("p",null,"Only specific categories and modes support AirPlay. The following categories support both the mirrored and non-mirrored versions of AirPlay:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSessionCategorySoloAmbient")),Object(a.b)("li",{parentName:"ul"},Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSessionCategoryAmbient")),Object(a.b)("li",{parentName:"ul"},Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSessionCategoryPlayback"))),Object(a.b)("p",null,"The ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionCategoryPlayAndRecord")," category and the following modes support only the mirrored version of AirPlay:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSessionModeDefault")),Object(a.b)("li",{parentName:"ul"},Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSessionModeVideoChat")),Object(a.b)("li",{parentName:"ul"},Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSessionModeGameChat"))),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Note:")," Starting in iOS 10, you can enable non-mirrored AirPlay output when using the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionCategoryPlayAndRecord")," category by activating your session with the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionCategoryOptionAllowAirPlay")," option."),Object(a.b)("h3",{id:"enabling-background-audio"},"Enabling background Audio"),Object(a.b)("p",null,"iOS and tvOS apps require you to enable certain capabilities for some background operations. A common capability required by playback apps is to play background audio. With this capability enabled, your app\u2019s audio can continue when users switch to another app or when they lock their iOS devices. This capability is also required for enabling advanced playback features like AirPlay streaming and Picture in Picture playback in iOS."),Object(a.b)("p",null,"The simplest way to configure these capabilities is by using Xcode. Select your app\u2019s target in Xcode and select the Capabilities tab. Under the Capabilities tab, set the Background Modes switch to ON and select the \u201cAudio, AirPlay, and Picture in Picture\u201d option from the list of available modes."),Object(a.b)("p",null,Object(a.b)("img",{alt:"../Art/background_modes.shot/Resources/shot_2x.png",src:o(489).default})),Object(a.b)("p",null,"With this background mode enabled and your audio session configured with an appropriate category, your app is ready to play background audio."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Note:")," To allow the audio portion of a video presentation to play in the background, see ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MediaPlaybackGuide/Contents/Resources/en.lproj/RefiningTheUserExperience/RefiningTheUserExperience.html#//apple_ref/doc/uid/TP40016757-CH6-SW9"},"Playing Background Audio")," in ",Object(a.b)("em",{parentName:"p"},Object(a.b)("a",{parentName:"em",href:"https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MediaPlaybackGuide/Contents/Resources/en.lproj/Introduction/Introduction.html#//apple_ref/doc/uid/TP40016757"},"Media Playback Programming Guide")),"."),Object(a.b)("h2",{id:"activating-an-audio-session"},"Activating an Audio Session"),Object(a.b)("h3",{id:"how-the-system-resolves-competing-audio-demands"},"How the System Resolves Competing Audio Demands"),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"\u7cfb\u7edf\u5982\u4f55\u89e3\u51b3\u7ade\u4e89\u97f3\u9891\u7684\u9700\u6c42 \uff08Competing Audio Demands\uff09")),Object(a.b)("p",null,"As your app launches, built-in apps (Messages, Music, Safari, the phone) may be running in the background. Each of these may produce audio: a text message arrives, a podcast you started 10 minutes ago continues playing, and so on."),Object(a.b)("p",null,"If you think of a device as an airport, with apps represented as taxiing airplanes, the system serves as a sort of control tower. Your app can make audio requests and state its desired priority, but final authority over what happens \u201con the tarmac\u201d comes from the system. You communicate with the \u201ccontrol tower\u201d using the audio session. Figure 2-1 illustrates a typical scenario\u2014your app asking to use audio while the Music app is already playing. In this scenario, your app interrupts the Music app."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Figure 2-1")," The system manages competing audio demands"),Object(a.b)("p",null,Object(a.b)("img",{alt:"A comic-book representation of the sequence of events surrounding the activation of an audio session.",src:o(490).default})),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"}," state its desired priority,\u58f0\u660e\u4ed6\u6240\u9700\u8981\u7684\u4f18\u5148\u7ea7"),Object(a.b)("p",{parentName:"blockquote"}," final authority over \u6700\u7ec8\u51b3\u5b9a\uff0c\u63a7\u5236")),Object(a.b)("p",null,"In step 1 of the figure, your app requests activation of its audio session. You\u2019d make such a request, for example, on app launch, or perhaps in response to a user tapping the Play button in an audio recording and playback app. In step 2, the system considers the activation request. Specifically, it considers the category you\u2019ve assigned to your audio session. In Figure 2-1, your app uses a category that requires other audio to be silenced."),Object(a.b)("p",null,"In steps 3 and 4, the system deactivates the Music app\u2019s audio session, stopping its audio playback. Finally, in step 5, the system activates your app\u2019s audio session and playback can begin."),Object(a.b)("h3",{id:"activity-and-deactivaty-you-audio-session"},"Activity and Deactivaty you Audio Session"),Object(a.b)("p",null,"Although the AVFoundation playback and recording classes automatically activate your audio session, manually activating it gives you an opportunity to test whether activation succeeded. However, if your app has a play/pause UI element, write your code so that the user must press Play before the session is activated. Likewise, when changing your audio session\u2019s active/inactive state, check to ensure that the call is successful. Write your code to gracefully handle the system\u2019s refusal to activate your session."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"gracefully handle \u59a5\u5584\u5904\u7406"),Object(a.b)("p",{parentName:"blockquote"},"refusal to activate your session. \u62d2\u7edd\u6fc0\u6d3b\u4f60\u7684session")),Object(a.b)("p",null,"The system deactivates your audio session for a Clock or Calendar alarm or an incoming phone call. When the user dismisses the alarm, or chooses to ignore a phone call, the system allows your session to become active again. Whether to reactivate a session at the end of an interruption depends on the app type, as described in ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioGuidelinesByAppType/AudioGuidelinesByAppType.html#//apple_ref/doc/uid/TP40007875-CH11-SW1"},"Audio Guidelines By App Type"),"."),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},'let session = AVAudioSession.sharedInstance()\ndo {\n    // 1) Configure your audio session category, options, and mode\n    // 2) Activate your audio session to enable your custom configuration\n    try session.setActive(true)\n} catch let error as NSError {\n    print("Unable to activate audio session:  \\(error.localizedDescription)")\n}\n')),Object(a.b)("p",null,"To deactivate your audio session, pass ",Object(a.b)("inlineCode",{parentName:"p"},"false")," to the ",Object(a.b)("inlineCode",{parentName:"p"},"setActive")," method."),Object(a.b)("p",null,"When playing or recording audio with an AVFoundation object (",Object(a.b)("inlineCode",{parentName:"p"},"AVPlayer"),", ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioRecorder"),", and so on), the system takes care of audio session reactivation upon interruption end. However, if you register for notification messages and explicitly reactivate your audio session, you can verify that reactivation succeeded, and you can update your app\u2019s state and user interface. For more information, see ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/HandlingAudioInterruptions/HandlingAudioInterruptions.html#//apple_ref/doc/uid/TP40007875-CH4-SW6"},"Figure 3-1"),"."),Object(a.b)("p",null,"Many apps never need to deactivate their audio session explicitly. Important exceptions include VoIP apps, turn-by-turn navigation apps, and, in some cases, playback and recording apps."),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Ensure that the audio session for a VoIP app, which usually runs in the background, is active only while the app is handling a call. In the background, standing ready to receive a call, a VoIP app\u2019s audio session should not be active."),Object(a.b)("li",{parentName:"ul"},"Ensure that the audio session for an app using a recording category is active only while recording. Before recording starts and when it stops, ensure that your session is inactive to allow other sounds, such as incoming message alerts, to play."),Object(a.b)("li",{parentName:"ul"},"If an app supports background audio playback or recording, deactivate its audio session when entering the background if the app is not actively using audio (or preparing to use audio). Doing so allows the system to free up audio resources so that they may be used by other processes. It also prevents the app's audio session from being deactivated when the app process is suspended by the operating system (see ",Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSessionInterruptionWasSuspendedKey"),").")),Object(a.b)("h3",{id:"checking-whether-other-audio-is-playing"},"Checking Whether Other Audio is Playing"),Object(a.b)("p",null,"When your app becomes active, sound may already be playing on the device. For example, the Music app may be playing a song when a user launches your app, or Safari may be streaming audio. Knowing if other audio is playing is especially important if your app is a game. Many games have a music sound track as well as sound effects. ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/ios/human-interface-guidelines/interaction/audio/"},"Audio")," in ",Object(a.b)("em",{parentName:"p"},"iOS Human Interface Guidelines")," advises you to assume that users expect the other audio to continue, along with the game\u2019s sound effects, as they play the game."),Object(a.b)("p",null,"In your app delegate\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"applicationDidBecomeActive:")," method, inspect the audio session\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"secondaryAudioShouldBeSilencedHint")," property to determine if audio is already playing. The value is ",Object(a.b)("inlineCode",{parentName:"p"},"true")," when another app with a nonmixable audio session is playing audio. Apps should use this property as a hint to silence audio that is secondary to the functioning of the app. For example, a game using ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionCategoryAmbient")," can use this property to determine if it should mute its soundtrack while leaving its sound effects unmuted."),Object(a.b)("p",null,"You can also subscribe to notifications of type ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionSilenceSecondaryAudioHintNotification")," to ensure that your app is notified when optional secondary audio muting should begin or end. This notification is sent only to registered listeners who are currently in the foreground and have an active audio session."),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},"func setupNotifications() {\n    NotificationCenter.default.addObserver(self,\n                                           selector: #selector(handleSecondaryAudio),\n                                           name: .AVAudioSessionSilenceSecondaryAudioHint,\n                                           object: AVAudioSession.sharedInstance())\n}\n \nfunc handleSecondaryAudio(notification: Notification) {\n    // Determine hint type\n    guard let userInfo = notification.userInfo,\n        let typeValue = userInfo[AVAudioSessionSilenceSecondaryAudioHintTypeKey] as? UInt,\n        let type = AVAudioSessionSilenceSecondaryAudioHintType(rawValue: typeValue) else {\n            return\n    }\n \n    if type == .begin {\n        // Other app audio started playing - mute secondary audio\n    } else {\n        // Other app audio stopped playing - restart secondary audio\n    }\n}\n")),Object(a.b)("p",null,"This notification's ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary contains an ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionSilenceSecondaryAudioHintType")," value for ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionSilenceSecondaryAudioHintTypeKey"),". Use the audio hint type to determine if your secondary audio muting should begin or end."),Object(a.b)("h2",{id:"responding-to-interruptions"},"Responding to interruptions"),Object(a.b)("p",null,"Adding audio session code to handle interruptions ensures that your app\u2019s audio continues behaving gracefully when a phone call arrives, a Clock or Calendar alarm sounds, or another app activates its audio session."),Object(a.b)("p",null,"An ",Object(a.b)("em",{parentName:"p"},"audio interruption")," is the deactivation of your app\u2019s audio session\u2014which immediately stops your audio. Interruptions happen when a competing audio session from an app is activated and that session is not categorized by the system to mix with yours. After your session goes inactive, the system sends a \u201cyou were interrupted\u201d message that you can respond to by saving state, updating the user interface, and so on."),Object(a.b)("p",null,"Your app may be suspended following an interruption. This happens when a user accepts a phone call. If a user instead ignores a call, or dismisses an alarm, the system issues an \u201cinterruption ended\u201d message, and your app continues running. For your audio to resume, you must reactivate your audio session."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"For your audio to resume, you must reactivate your audio session. \u8981\u6062\u590daudio \u5fc5\u987b\u91cd\u65b0\u6fc0\u6d3bsession")),Object(a.b)("h3",{id:"the-interruption-life-cycle"},"The Interruption Life Cycle"),Object(a.b)("p",null,"Figure 3-1 illustrates the sequence of events before, during, and after an audio session interruption for a playback app."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Figure 3-1")," An audio session is interrupted",Object(a.b)("img",{alt:"A timeline representation of an application&#39;s audio session getting interrupted by a phone call.",src:o(491).default})),Object(a.b)("p",null,"An interruption event\u2014in this example, the arrival of a FaceTime request\u2014proceeds as follows. The numbered steps correspond to the numbers in the figure."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"proceeds as follows \u53d1\u751f\u5982\u4e0b\u4e8b\u4ef6"),Object(a.b)("p",{parentName:"blockquote"},"correspond to \u7b26\u5408\u5bf9\u5e94")),Object(a.b)("p",null,"An interruption event\u2014in this example, the arrival of a FaceTime request\u2014proceeds as follows. The numbered steps correspond to the numbers in the figure."),Object(a.b)("ol",null,Object(a.b)("li",{parentName:"ol"},"Your app is active, playing back audio."),Object(a.b)("li",{parentName:"ol"},"A FaceTime request arrives. The system activates the FaceTime app\u2019s audio session."),Object(a.b)("li",{parentName:"ol"},"The system deactivates your audio session. At this point, playback in your app has stopped."),Object(a.b)("li",{parentName:"ol"},"The system posts a notification, indicating that your session has been deactivated."),Object(a.b)("li",{parentName:"ol"},"Your notification handler takes appropriate action. For example, it could update the user interface and save the information needed to resume playback at the point where it stopped."),Object(a.b)("li",{parentName:"ol"},"If the user dismisses the interruption\u2014ignoring the incoming FaceTime request\u2014the system posts a notification, indicating that the interruption has ended."),Object(a.b)("li",{parentName:"ol"},"Your notification handler takes action appropriate to the end of an interruption. For example, it might update the user interface, reactivate the audio session, and resume playback."),Object(a.b)("li",{parentName:"ol"},"(Not shown in the figure.) If, instead of dismissing the interruption at step 6, the user accepts a phone call, your app is suspended.")),Object(a.b)("h3",{id:"audio-interruption-handling-techniques"},"Audio Interruption handling Techniques"),Object(a.b)("p",null,"Handle interruptions by registering to observe interruption notifications posted by ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSession"),". What you do within your interruption code depends on the audio technology you are using and on what you are using it for\u2014playback, recording, audio format conversion, reading streamed audio packets, and so on. Generally speaking, you need to ensure the minimum possible disruption, and the most graceful possible recovery, from the perspective of the user."),Object(a.b)("p",null,"Table 3-1 summarizes appropriate audio session behavior during an interruption. If you use AVFoundation playback or recording objects, some of these steps are handled automatically by the system."),Object(a.b)("table",null,Object(a.b)("thead",{parentName:"table"},Object(a.b)("tr",{parentName:"thead"},Object(a.b)("th",{parentName:"tr",align:null},Object(a.b)("em",{parentName:"th"},"After interruption starts")),Object(a.b)("th",{parentName:"tr",align:null},"Save state and contextUpdate user interface"))),Object(a.b)("tbody",{parentName:"table"},Object(a.b)("tr",{parentName:"tbody"},Object(a.b)("td",{parentName:"tr",align:null},Object(a.b)("em",{parentName:"td"},"After interruption ends")),Object(a.b)("td",{parentName:"tr",align:null},"Restore state and contextUpdate user interfaceReactivate audio session, if appropriate for the app")))),Object(a.b)("p",null,"Table 3-2 summarizes how to handle audio interruptions according to technology. The rest of this chapter provides details."),Object(a.b)("table",null,Object(a.b)("thead",{parentName:"table"},Object(a.b)("tr",{parentName:"thead"},Object(a.b)("th",{parentName:"tr",align:"left"},"Audio technology"),Object(a.b)("th",{parentName:"tr",align:"left"},"How interruptions work"))),Object(a.b)("tbody",{parentName:"table"},Object(a.b)("tr",{parentName:"tbody"},Object(a.b)("td",{parentName:"tr",align:"left"},"AVFoundation framework"),Object(a.b)("td",{parentName:"tr",align:"left"},"The system automatically pauses playback or recording upon interruption and reactivates your audio session when you resume playback or recording.If you want to save and restore the playback position between app launches, save the playback position on interruption as well as on app quit.")),Object(a.b)("tr",{parentName:"tbody"},Object(a.b)("td",{parentName:"tr",align:"left"},"Audio Queue Services, I/O audio unit"),Object(a.b)("td",{parentName:"tr",align:"left"},"These technologies put your app in control of handling interruptions. You are responsible for saving playback or recording position and for reactivating your audio session after the interruption ends.")),Object(a.b)("tr",{parentName:"tbody"},Object(a.b)("td",{parentName:"tr",align:"left"},"System Sound Services"),Object(a.b)("td",{parentName:"tr",align:"left"},"Sounds played using System Sound Services go silent when an interruption starts. The sounds are eligible to be played again if the interruption ends. Apps cannot influence the interruption behavior for sounds that use this playback technology.")))),Object(a.b)("h3",{id:"handling-interruption-from-siri"},"Handling Interruption from Siri"),Object(a.b)("p",null,"When Siri interrupts your app\u2019s playback, you must keep track of any remote control commands issued by Siri while the audio session is in an interrupted state. During the interruption, keep track of any commands issued by Siri and respond accordingly when the interruption ends. For example, during the interruption, the user asks Siri to pause your app\u2019s audio playback. When your app is notified that the interruption has ended, it should not automatically resume playing. Instead, your app\u2019s UI should indicate that the app is in a paused state."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"you must keep track of any remote control commands issued by Siri \u8ddf\u8e2asiri\u53d1\u51fa\u7684\u547d\u4ee4")),Object(a.b)("h3",{id:"observer-audio-interruptions"},"Observer Audio Interruptions"),Object(a.b)("p",null,"To handle audio interruptions, begin by registering to observe notifications of type AVAudioSessionInterruptionNotification."),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},"func registerForNotifications() {\n    NotificationCenter.default.addObserver(self,\n                                           selector: #selector(handleInterruption),\n                                           name: .AVAudioSessionInterruption,\n                                           object: AVAudioSession.sharedInstance())\n}\n \nfunc handleInterruption(_ notification: Notification) {\n    // Handle interruption\n}\n")),Object(a.b)("p",null,"The posted ",Object(a.b)("inlineCode",{parentName:"p"},"NSNotification")," instance contains a populated ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary providing the details of the interruption. You determine the type of interruption by retrieving the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionInterruptionType")," value from the ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary. The interruption type indicates whether the interruption has begun or has ended."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"a populated ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary \u4e00\u4e2a\u586b\u5145\u7684userinfo \u5b57\u5178"),Object(a.b)("p",{parentName:"blockquote"},"You determine the type of interruption \u4f60\u9700\u8981\u786e\u5b9a\u4e2d\u65ad\u7684\u7c7b\u578b"),Object(a.b)("p",{parentName:"blockquote"},"by retrieving the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionInterruptionType")," value from the ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary \u901a\u8fc7\u68c0\u7d22AVAudioSessionInterruptionType \u7684\u503c"),Object(a.b)("p",{parentName:"blockquote"},"The interruption type indicates whether the interruption has begun or has ended. \u4e2d\u65ad\u7c7b\u578b\u6307\u793a\uff0c\u4e2d\u65ad\u662f\u5f00\u59cb\u8fd8\u662f\u7ed3\u675f")),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},"func handleInterruption(_ notification: Notification) {\n    guard let info = notification.userInfo,\n        let typeValue = info[AVAudioSessionInterruptionTypeKey] as? UInt,\n        let type = AVAudioSessionInterruptionType(rawValue: typeValue) else {\n            return\n    }\n    if type == .began {\n        // Interruption began, take appropriate actions (save state, update user interface)\n    }\n    else if type == .ended {\n        guard let optionsValue =\n            userInfo[AVAudioSessionInterruptionOptionKey] as? UInt else {\n                return\n        }\n        let options = AVAudioSessionInterruptionOptions(rawValue: optionsValue)\n        if options.contains(.shouldResume) {\n            // Interruption Ended - playback should resume\n        }\n    }\n}\n")),Object(a.b)("p",null,"If the interruption type is ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionInterruptionTypeEnded"),", the ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary might contain an ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionInterruptionOptions")," value. An options value of ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionInterruptionOptionShouldResume")," is a hint that indicates whether your app should automatically resume playback if it had been playing when it was interrupted. Media playback apps should always look for this flag before beginning playback after an interruption. If it\u2019s not present, playback should not begin again until initiated by the user. Apps that don\u2019t present a playback interface, such as a game, can ignore this flag and reactivate and resume playback when the interruption ends."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"Media playback apps \u5a92\u4f53\u64ad\u653eapp"),Object(a.b)("p",{parentName:"blockquote"},"should always look for this flag \u5e94\u8be5\u5bfb\u627e\u6b64\u6807\u8bc6"),Object(a.b)("p",{parentName:"blockquote"}," If it\u2019s not present, playback should not begin again until initiated by the user. \u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5219\u5728\u7528\u6237\u64ad\u653e\u4e4b\u524d\u4e0d\u5e94\u91cd\u65b0\u5feb\u5f00\u59cb\u64ad\u653e\u3002"),Object(a.b)("p",{parentName:"blockquote"},"Apps that don\u2019t present a playback interface \u672a\u63d0\u4f9b\u64ad\u653e\u754c\u9762\u7684APP")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Note:")," There is no guarantee that a begin interruption will have a corresponding end interruption. Your app needs to be aware of a switch to a foreground running state or the user pressing a Play button. In either case, determine whether your app should reactivate its audio session."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"There is no guarantee that a begin interruption will have a corresponding end interruption.  \u4e0d\u4fdd\u8bc1\uff0c\u5f00\u59cb\u4e2d\u65ad\u4f1a\u4ea7\u751f\u76f8\u5e94\u5b9a\u7684\u7ed3\u675f\u4e2d\u65ad"),Object(a.b)("p",{parentName:"blockquote"},"be aware of \u9700\u8981\u77e5\u9053"),Object(a.b)("p",{parentName:"blockquote"},"In either case \u65e0\u8bba\u54ea\u79cd\u60c5\u51b5")),Object(a.b)("h3",{id:"responding--to-a-media-server-reset"},"Responding  to a media server Reset"),Object(a.b)("p",null,"The media server provides audio and other multimedia functionality through a shared server process. Although rare, it\u2019s possible for the media server to reset while your app is active. Register for the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionMediaServicesWereResetNotification")," notification to monitor for a media server reset. After receiving the notification, your app needs to do the following:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Dispose of orphaned audio objects (such as players, recorders, converters, or audio queues) and create new ones"),Object(a.b)("li",{parentName:"ul"},"Reset any internal audio states being tracked, including all properties of ",Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSession")),Object(a.b)("li",{parentName:"ul"},"When appropriate, reactivate the ",Object(a.b)("inlineCode",{parentName:"li"},"AVAudioSession")," instance using the ",Object(a.b)("inlineCode",{parentName:"li"},"setActive:error:")," method")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Important:")," Apps do not need to re-register for any ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSession")," notifications or reset key-value observers on ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSession")," properties."),Object(a.b)("p",null,"You can also register for the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionMediaServicesWereLostNotification")," notification if you want to know when the media server first becomes unavailable. However, most apps only need to respond to the reset notification. Use the lost notification only if the app must respond to user events that occur after the media server is lost, but before the media server is reset."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Note:")," You can trigger a media server crash and restart by choosing Reset Media Services from the Developer menu in Settings. Using this utility makes it easy for you to ensure that your app responds appropriately if media services are reset."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"Although rare,  \u5c3d\u7ba1\u7f55\u89c1")),Object(a.b)("h2",{id:"responding-to-route-changes"},"Responding to Route Changes"),Object(a.b)("p",null,"As your app runs, a user might plug in or unplug a headset, or use a docking station with audio connections."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"might plug in or unplug a headset \u53ef\u80fd\u4f1a\u63d2\u5165\u6216\u8005\u62d4\u51fa\u8033\u673a\uff0c"),Object(a.b)("p",{parentName:"blockquote"},"or use a docking station with audio connections.  \u6216\u8005\u4f7f\u7528\u5e26\u6709\u97f3\u9891\u8fde\u63a5\u7684\u6269\u5c55\u575e")),Object(a.b)("p",null,"To implement the recommendations, write audio session code to handle audio hardware route changes. Certain types of apps, like games, don\u2019t always have to respond to route changes. However, other types of apps, such as media players, must respond to all route changes."),Object(a.b)("h3",{id:"varieties-of-audio-hardware-route-change"},"Varieties Of Audio Hardware Route Change"),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"\u5404\u79cd\u97f3\u9891\u786c\u4ef6\u8def\u7531\u53d8\u5316")),Object(a.b)("p",null,"An audio hardware route is a wired electronic pathway for audio signals.When a user of a device plugs in or unplugs a headset, the system automatically changes the audio hardware route. Your app can be notified of such changes if you register to observe notifications of type AVAudioSessionRouteChangeNotification."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"An audio hardware route is a wired electronic pathway for audio signals \u97f3\u9891\u786c\u4ef6\u8def\u7531\u662f \u97f3\u9891\u4fe1\u53f7\u7684\u6709\u7ebf\u7535\u5b50\u8def\u5f84")),Object(a.b)("p",null,"Figure 4-1 depicts the sequence of events for various route changes during recording and playback. The four possible outcomes, shown across the bottom of the figure, result from actions taken by a property listener callback function that you write."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Figure 4-1")," Handling audio hardware route changes",Object(a.b)("img",{alt:"A flowchart representation of how Core Audio, and your property listener callback function, interact to provide good user experience upon an audio hardware route change.",src:o(492).default})),Object(a.b)("p",null,"As shown in the figure, the system initially determines the audio route after your app launches. It continues to monitor the active route as your app runs. Consider first the case of a user tapping the Record button in your app, represented by the \u201cRecording starts\u201d box on the left side of the figure."),Object(a.b)("p",null,"During recording, the user may plug in or unplug a headset\u2014see the diamond-shaped decision element toward the lower-left of the figure. In response, the system sends a route change notification containing the reason for the change, and the previous route. Your app should stop recording."),Object(a.b)("p",null,"The case for playback is similar but has different outcomes, as shown on the right of the figure. If a user unplugs the headset during playback, your app should pause the audio. If a user plugs in the headset during playback, your app should simply allow playback to continue."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"}," the system initially determines the audio route after your app launches\u3002 APP \u542f\u52a8\u540e\u7cfb\u7edf\u6700\u521d\u51b3\u5b9a\u97f3\u9891\u8def\u7531\u3002")),Object(a.b)("h3",{id:"observering-audio-route-changes"},"Observering Audio Route Changes"),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"\u76d1\u542c\u97f3\u9891\u8def\u7531\u53d8\u5316")),Object(a.b)("p",null,"Audio route changes occur for a number of reasons, including a user plugging in a pair of headphones, connecting a Bluetooth LE headset, or unplugging a USB audio interface. Knowing when these changes occur may be important to your app so you can update its user interface or change its internal state. You can be notified of audio route changes by registering to observe notifications of type ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteChangeNotification"),"."),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},"func setupNotifications() {\n    NotificationCenter.default.addObserver(self,\n                                           selector: #selector(handleRouteChange),\n                                           name: .AVAudioSessionRouteChange,\n                                           object: AVAudioSession.sharedInstance())\n}\n \nfunc handleRouteChange(_ notification: Notification) {\n \n}\n")),Object(a.b)("p",null,"The posted notification contains a populated ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary providing the details of the route change. You can determine the reason for this change by retrieving the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteChangeReason")," value from the ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary. When a new device is connected, the reason is ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteChangeReasonNewDeviceAvailable"),", and when one is removed, it is ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteChangeReasonOldDeviceUnavailable"),"."),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},"func handleRouteChange(_ notification: Notification) {\n    guard let userInfo = notification.userInfo,\n        let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,\n        let reason = AVAudioSessionRouteChangeReason(rawValue:reasonValue) else {\n            return\n    }\n    switch reason {\n    case .newDeviceAvailable:\n        // Handle new device available.\n    case .oldDeviceUnavailable:\n        // Handle old device removed.\n    default: ()\n    }\n}\n")),Object(a.b)("p",null,"When a new device becomes available, you query the audio session\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"currentRoute")," property to determine where the audio output is currently routed. This returns an ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteDescription")," object listing all of the audio session\u2019s inputs and outputs. When a device is removed, you retrieve the ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteDescription")," object for the ",Object(a.b)("em",{parentName:"p"},"previous")," route from the ",Object(a.b)("inlineCode",{parentName:"p"},"userInfo")," dictionary. In both cases, you query the route description\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"outputs")," property, which returns an array of ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionPortDescription")," objects providing the details of the audio output routes."),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},"func handleRouteChange(notification: NSNotification) {\n    guard let userInfo = notification.userInfo,\n        let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,\n        let reason = AVAudioSessionRouteChangeReason(rawValue:reasonValue) else {\n            return\n    }\n    switch reason {\n    case .newDeviceAvailable:\n        let session = AVAudioSession.sharedInstance()\n        for output in session.currentRoute.outputs where output.portType == AVAudioSessionPortHeadphones {\n            headphonesConnected = true\n        }\n    case .oldDeviceUnavailable:\n        if let previousRoute =\n            userInfo[AVAudioSessionRouteChangePreviousRouteKey] as? AVAudioSessionRouteDescription {\n            for output in previousRoute.outputs where output.portType == AVAudioSessionPortHeadphones {\n                headphonesConnected = false\n            }\n        }\n    default: ()\n    }\n}\n")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Important:")," Media playback apps should pause playback if the route change reason is ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteChangeReasonOldDeviceUnavailable"),", but should not if the reason is ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionRouteChangeReasonOverride"),"."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Note:")," An audio route change may also result in changes to the audio session\u2019s sample rate, I/O buffer duration, channel counts, or other hardware-related values. If these values are important to your app, query them after a route change to see if their values have changed."),Object(a.b)("h2",{id:"configuring-device-hardware"},"Configuring Device Hardware"),Object(a.b)("p",null,"Using audio session properties, you can optimize your app\u2019s audio behavior for device hardware at runtime. Doing this lets your code adapt to the characteristics of the device it\u2019s running on, as well as to changes made by the user (such as plugging in a headset or docking the device) as your app runs."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"Using audio session properties \u4f7f\u7528audio session \u5c5e\u6027"),Object(a.b)("p",{parentName:"blockquote"},"optimize\uff1a \u4f18\u5316")),Object(a.b)("p",null,"Use ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSession")," to:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Specify your preferred hardware settings for sample rate and I/O buffer duration"),Object(a.b)("li",{parentName:"ul"},"Query many hardware characteristics, such as input and output latency, input and output channel count, hardware sample rate, hardware volume setting, and availability of audio input")),Object(a.b)("h3",{id:"choosing-preferred-audio-hardware-values"},"Choosing Preferred Audio Hardware Values"),Object(a.b)("p",null,"Use the audio session to specify your preferred device settings, such as sample rate and hardware I/O buffer duration. Table 5-1 describes the benefits and costs of these preferences."),Object(a.b)("p",null,Object(a.b)("img",{alt:"image-20210124171039521",src:o(493).default})),Object(a.b)("p",null,"For example, you might specify a preference for a high sample rate if audio quality is very important in your app, and if large file or buffer size is not a significant issue."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Note:")," The default audio I/O buffer duration (about 0.02 seconds for 44.1 kHz audio) provides sufficient responsiveness for most apps. You can set a lower I/O duration for latency-critical apps such as live musical instrument monitoring, but you\u2019ll never need to modify this setting for most apps."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"latency-critical apps. \u4f4e\u5ef6\u8fdf\u7684\u5173\u952e\u5e94\u7528"),Object(a.b)("p",{parentName:"blockquote"},"is not a significant issue. \u4e0d\u662f\u4e00\u4e2a\u5927\u95ee\u9898")),Object(a.b)("h3",{id:"setting-preferred-audio-hardware-values"},"Setting Preferred Audio Hardware Values"),Object(a.b)("p",null,"Set preferred hardware values before you activate your audio session. If you're already running an audio session, deactivate it. Changes to preferred values take effect after the audio session is activated, and you can verify the changes at that time. Listing 5-1 shows how to set preferred hardware values and how to verify them."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Listing 5-1")," Setting and verifying audio hardware values"),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},'let session = AVAudioSession.sharedInstance()\n \n// Configure category and mode\ndo {\n    try session.setCategory(AVAudioSessionCategoryRecord, mode: AVAudioSessionModeDefault)\n} catch let error as NSError {\n    print("Unable to set category:  \\(error.localizedDescription)")\n}\n \n// Set preferred sample rate\ndo {\n    try session.setPreferredSampleRate(44_100)\n} catch let error as NSError {\n    print("Unable to set preferred sample rate:  \\(error.localizedDescription)")\n}\n \n// Set preferred I/O buffer duration\ndo {\n    try session.setPreferredIOBufferDuration(0.005)\n} catch let error as NSError {\n    print("Unable to set preferred I/O buffer duration:  \\(error.localizedDescription)")\n}\n \n// Activate the audio session\ndo {\n    try session.setActive(true)\n} catch let error as NSError {\n    print("Unable to activate session. \\(error.localizedDescription)")\n}\n \n// Query the audio session\'s ioBufferDuration and sampleRate properties\n// to determine if the preferred values were set\nprint("Audio Session ioBufferDuration: \\(session.ioBufferDuration), sampleRate: \\(session.sampleRate)")\n')),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"to determine if the preferred values were set \u53bb\u51b3\u5b9a\u662f\u5426\u8bbe\u7f6e\u4e86\u9996\u9009\u503c")),Object(a.b)("p",null,"Note: When competing audio sessions set preferred hardware values, the system gives priority to nonmixable sessions. An audio session using the AVAudioSessionCategoryAmbient category or the AVAudioSessionCategoryOptionMixWithOthers option is unlikely to have its preferred hardware settings honored."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"the system gives priority to nonmixable session \u7cfb\u7edf\u4f1a\u7ed9\u4e0d\u6df7\u5408\u7684\u4f1a\u8bdd\u4f18\u5148\u7ea7")),Object(a.b)("h3",{id:"selecting-and-configuring-microphones"},"Selecting And Configuring Microphones"),Object(a.b)("p",null,"On devices with two or more built-in microphones, iOS automatically selects a microphone through the use of audio session modes. A mode specifies the digital signal processing (DSP) used for input, and the possible routes. The input and routes are optimized for each mode's use case. Setting a mode may also affect other aspects of the route being used."),Object(a.b)("p",null,"Developers can also manually select microphones and even select a preferred microphone polar pattern if the hardware supports it."),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"through the use of audio session modes.  \u901a\u8fc7\u4f7f\u7528\u7684session modes\u3002")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Important:")," Before using any of the input selection features, set the audio session category and mode for your app, and then activate the audio session."),Object(a.b)("h4",{id:"setting-a-preferred-input"},"Setting a Preferred Input"),Object(a.b)("p",null,"To discover built-in or connected input ports, use the audio session\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"availableInputs")," property. This property returns an array of ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionPortDescription")," objects that describe the device\u2019s available input ports. Ports can be identified by their ",Object(a.b)("inlineCode",{parentName:"p"},"portType")," property. To set a preferred input port (built-in microphone, wired microphone, USB input, and so on) use the audio session\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"setPreferredInput:error:")," method."),Object(a.b)("h4",{id:"setting-a-preferred-datasource"},"Setting a Preferred DataSource"),Object(a.b)("p",null,"Some ports, such as the built-in microphone and some USB accessories, support data sources. Apps can discover available data sources by querying the port description\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"dataSources")," property. In the case of the built-in microphone, the returned data source description objects represent each individual microphone. Different devices return different values for the built-in mic. For instance, the iPhone 4 and iPhone 4S have two microphones: bottom and top. The iPhone 5 has three microphones: bottom, front, and back."),Object(a.b)("p",null,"Individual built-in microphones may be identified by a combination of a data source description\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"location")," property (upper, lower) and ",Object(a.b)("inlineCode",{parentName:"p"},"orientation")," property (front, back, and so on). Apps may set a preferred data source by using the ",Object(a.b)("inlineCode",{parentName:"p"},"setPreferredDataSource:error:")," method of an ",Object(a.b)("inlineCode",{parentName:"p"},"AVAudioSessionPortDescription")," object."),Object(a.b)("h4",{id:"setting-a-preferred-polar-pattern"},"Setting a Preferred Polar Pattern"),Object(a.b)("p",null,"Some iOS devices support configuring microphone polar patterns for some of the built-in microphones. A microphone\u2019s polar pattern defines its sensitivity to sound relative to the direction of the sound source. Current-generation iPhones support setting the preferred polar pattern for the front and back built-in microphones. Available patterns are returned using the ",Object(a.b)("inlineCode",{parentName:"p"},"supportedPolarPatterns")," property of a data source description object. This property returns either an array of supported polar patterns for the data source, such as cardioid or omnidirectional, or ",Object(a.b)("inlineCode",{parentName:"p"},"nil")," when no selectable patterns are available. If the data source has a number of supported polar patterns, you can set the preferred polar pattern by using the data source description\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"setPreferredPolarPattern:error:")," method."),Object(a.b)("h4",{id:"putting-it-all-together"},"Putting it all Together"),Object(a.b)("p",null,"The following code provides a simple example illustrating how to select a particular microphone and set its polar pattern."),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},'// Preferred Mic = Front, Preferred Polar Pattern = Cardioid\nlet preferredMicOrientation = AVAudioSessionOrientationFront\nlet preferredPolarPattern = AVAudioSessionPolarPatternCardioid\n \n// Retrieve your configured and activated audio session\nlet session = AVAudioSession.sharedInstance()\n \n// Get available inputs\nguard let inputs = session.availableInputs else { return }\n \n// Find built-in mic\nguard let builtInMic = inputs.first(where: {\n    $0.portType == AVAudioSessionPortBuiltInMic\n}) else { return }\n \n// Find the data source at the specified orientation\nguard let dataSource = builtInMic.dataSources?.first (where: {\n    $0.orientation == preferredMicOrientation\n}) else { return }\n \n// Set data source\'s polar pattern\ndo {\n    try dataSource.setPreferredPolarPattern(preferredPolarPattern)\n} catch let error as NSError {\n    print("Unable to preferred polar pattern: \\(error.localizedDescription)")\n}\n \n// Set the data source as the input\'s preferred data source\ndo {\n    try builtInMic.setPreferredDataSource(dataSource)\n} catch let error as NSError {\n    print("Unable to preferred dataSource: \\(error.localizedDescription)")\n}\n \n// Set the built-in mic as the preferred input\n// This call will be a no-op if already selected\ndo {\n    try session.setPreferredInput(builtInMic)\n} catch let error as NSError {\n    print("Unable to preferred input: \\(error.localizedDescription)")\n}\n \n// Print Active Configuration\nsession.currentRoute.inputs.forEach { portDesc in\n    print("Port: \\(portDesc.portType)")\n    if let ds = portDesc.selectedDataSource {\n        print("Name: \\(ds.dataSourceName)")\n        print("Polar Pattern: \\(ds.selectedPolarPattern ?? "[none]")")\n    }\n}\n')),Object(a.b)("p",null,"Running this code on an iPhone 6s produces the following console output:"),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre"},"Port: MicrophoneBuiltIn\nName: Front\nPolar Pattern: Cardioid\n")),Object(a.b)("h3",{id:"runing-your-app-in-simulator"},"Runing your app in simulator"),Object(a.b)("p",null,"When you add audio session support to your app, you can run your app in Simulator or on a device. However, Simulator does not simulate most interactions between audio sessions in different processes or audio route changes. When running your app in Simulator, you cannot:"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Invoke an interruption"),Object(a.b)("li",{parentName:"ul"},"Simulate plugging in or unplugging a headset"),Object(a.b)("li",{parentName:"ul"},"Change the setting of the Silent switch"),Object(a.b)("li",{parentName:"ul"},"Simulate screen lock"),Object(a.b)("li",{parentName:"ul"},"Test audio mixing behavior\u2014that is, playing your audio along with audio from another app (such as the Music app)")),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"}," Simulator does not simulate most interactions between audio sessions in different processes or audio route changes.  \u6a21\u62df\u5668\u4e0d\u80fd\u6a21\u62df\u5f88\u591a\u573a\u666f"),Object(a.b)("p",{parentName:"blockquote"},"Simulate plugging in or unplugging a headset \u6a21\u62df\u63d2\u5165\uff0c\u62d4\u51fa\u8033\u673a")),Object(a.b)("p",null,"Because of the characteristics of Simulator, you may want to conditionalize your code to allow partial testing in Simulator. Listing 5-2 shows how to do this."),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Listing 5-2")," Using a conditional compilation block"),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},"#if arch(i386) || arch(x86_64)\n    // Execute subset of code that works in the Simulator\n#else\n    // Execute device-only code as well as the other code\n#endif\n")),Object(a.b)("blockquote",null,Object(a.b)("p",{parentName:"blockquote"},"conditionalize your code \u6761\u4ef6\u5316\u4f60\u7684\u4ee3\u7801"),Object(a.b)("p",{parentName:"blockquote"},"allow partial testing in Simulator \u5141\u8bb8\u5728\u6a21\u62df\u5668\u4e2d\u90e8\u5206\u8bbe\u7f6e"),Object(a.b)("p",{parentName:"blockquote"},"Using a conditional compilation block \u4f7f\u7528\u6761\u4ef6\u7f16\u8bd1\u5757")),Object(a.b)("h2",{id:"protecting-user-privacy"},"Protecting User Privacy"),Object(a.b)("p",null,"To protect user privacy, your app must ask and receive permission from the user before recording audio. If the user does not grant permission, then only silence is recorded. The system automatically prompts the user for permission when you use a category that supports recording and the app attempts to use an input route."),Object(a.b)("h3",{id:"requesting-permission-to-record-audio"},"Requesting Permission to Record Audio"),Object(a.b)("p",null,"Instead of waiting for the system to prompt the user for permission to record, you can use the ",Object(a.b)("inlineCode",{parentName:"p"},"requestRecordPermission:")," method to manually ask for permission. Using this method allows your app to get permission without interrupting the natural flow of the app, resulting in a better user experience."),Object(a.b)("pre",null,Object(a.b)("code",{parentName:"pre",className:"language-swift"},"AVAudioSession.sharedInstance().requestRecordPermission { granted in\n    if granted {\n        // User granted access. Present recording interface.\n    } else {\n        // Present message to user indicating that recording\n        // can't be performed until they change their preference\n        // under Settings -> Privacy -> Microphone\n    }\n}\n")),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Important:")," As of iOS 10, all apps that access any of the device's microphones must statically declare their intent to do so. To do this, apps must now include the ",Object(a.b)("inlineCode",{parentName:"p"},"NSMicrophoneUsageDescription")," key in their ",Object(a.b)("inlineCode",{parentName:"p"},"Info.plist")," file and provide a purpose string for this key. When the system prompts the user to allow access, this string is displayed as part of the alert."),Object(a.b)("p",null,"If an app attempts to access any of the device's microphones without this key and value present, the app will terminate."),Object(a.b)("h2",{id:"appendix-a-audio-guideline-by-app-type"},"Appendix A: Audio Guideline By App Type"),Object(a.b)("h3",{id:"audio-guidelines-for-game-apps"},"Audio Guidelines for Game Apps"),Object(a.b)("h3",{id:"audio-guidelines-for-user-controlled-playback-and-recording-apps"},"Audio Guidelines for User-Controlled Playback and Recording Apps"),Object(a.b)("h3",{id:"audio-guidelines-for-voip-and-chat-apps"},"Audio Guidelines for VoIP and Chat Apps"),Object(a.b)("h3",{id:"audio-guidelines-for-metering-apps"},"Audio Guidelines for Metering Apps"),Object(a.b)("h3",{id:"audio-guidelines-for-browser-like-apps-that-sometimes-play-audio"},"Audio Guidelines for Browser-like Apps That Sometimes Play Audio"),Object(a.b)("h3",{id:"audio-guidelines-for-navigation-and-workout-apps"},"Audio Guidelines for Navigation and Workout Apps"),Object(a.b)("h3",{id:"audio-guidelines-for-cooperative-music-apps"},"Audio Guidelines for Cooperative Music Apps"),Object(a.b)("h2",{id:"appendix-b-audio-session-categories-and-modes"},"Appendix B: Audio Session Categories and Modes"),Object(a.b)("p",null,"You specify an audio session category to express how you intend to use audio in your app. Table B-1 provides details about each of the available categories. For an explanation of how categories work, see ",Object(a.b)("a",{parentName:"p",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionBasics/AudioSessionBasics.html#//apple_ref/doc/uid/TP40007875-CH3-SW1"},"Configuring an Audio Session"),"."),Object(a.b)("p",null,Object(a.b)("img",{alt:"image-20210124210614014",src:o(494).default})),Object(a.b)("p",null,Object(a.b)("strong",{parentName:"p"},"Note:")," For your app to continue playing audio when the Ring/Silent switch is set to silent and the screen is locked, make sure the ",Object(a.b)("inlineCode",{parentName:"p"},"UIBackgroundModes")," ",Object(a.b)("inlineCode",{parentName:"p"},"audio")," key has been added to your app\u2019s ",Object(a.b)("inlineCode",{parentName:"p"},"Info.plist")," file. This requirement is in addition to your using the correct category."),Object(a.b)("p",null,"Table B-2 provides a list of modes and the categories each mode can be used with."),Object(a.b)("p",null,"Table B-2  Modes and associated categories"),Object(a.b)("p",null,Object(a.b)("img",{alt:"image-20210124210657041",src:o(495).default})),Object(a.b)("h2",{id:"reference"},"Reference"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},"Apple document: ",Object(a.b)("a",{parentName:"li",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html"},"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html"))),Object(a.b)("p",null,"Audio Session \u53c2\u8003\uff1a"),Object(a.b)("ul",null,Object(a.b)("li",{parentName:"ul"},Object(a.b)("a",{parentName:"li",href:"https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html"},"Audio Session Programming Guide")),Object(a.b)("li",{parentName:"ul"},Object(a.b)("a",{parentName:"li",href:"https://juejin.cn/post/6844903834385383431"},"Audio Session:\u7cfb\u7edf\u4e0e\u5e94\u7528\u7a0b\u5e8f\u7684\u4e2d\u4ecb")," "),Object(a.b)("li",{parentName:"ul"},Object(a.b)("a",{parentName:"li",href:"http://www.samirchen.com/ios-avaudiosession-3/"},"AVAudioSession(3)\uff1a\u5b9a\u5236 Audio Session \u7684 Category"))),Object(a.b)("p",null,Object(a.b)("a",{parentName:"p",href:"https://stackoverflow.com/questions/15643516/list-available-output-audio-target-avaudiosession"},"https://stackoverflow.com/questions/15643516/list-available-output-audio-target-avaudiosession")))}d.isMDXComponent=!0},356:function(e,t,o){"use strict";o.d(t,"a",(function(){return d})),o.d(t,"b",(function(){return h}));var i=o(0),n=o.n(i);function a(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function r(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,i)}return o}function s(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?r(Object(o),!0).forEach((function(t){a(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):r(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function u(e,t){if(null==e)return{};var o,i,n=function(e,t){if(null==e)return{};var o,i,n={},a=Object.keys(e);for(i=0;i<a.length;i++)o=a[i],t.indexOf(o)>=0||(n[o]=e[o]);return n}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)o=a[i],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(n[o]=e[o])}return n}var p=n.a.createContext({}),c=function(e){var t=n.a.useContext(p),o=t;return e&&(o="function"==typeof e?e(t):s(s({},t),e)),o},d=function(e){var t=c(e.components);return n.a.createElement(p.Provider,{value:t},e.children)},l={inlineCode:"code",wrapper:function(e){var t=e.children;return n.a.createElement(n.a.Fragment,{},t)}},b=n.a.forwardRef((function(e,t){var o=e.components,i=e.mdxType,a=e.originalType,r=e.parentName,p=u(e,["components","mdxType","originalType","parentName"]),d=c(o),b=i,h=d["".concat(r,".").concat(b)]||d[b]||l[b]||a;return o?n.a.createElement(h,s(s({ref:t},p),{},{components:o})):n.a.createElement(h,s({ref:t},p))}));function h(e,t){var o=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var a=o.length,r=new Array(a);r[0]=b;var s={};for(var u in t)hasOwnProperty.call(t,u)&&(s[u]=t[u]);s.originalType=e,s.mdxType="string"==typeof e?e:i,r[1]=s;for(var p=2;p<a;p++)r[p]=o[p];return n.a.createElement.apply(null,r)}return n.a.createElement.apply(null,o)}b.displayName="MDXCreateElement"},487:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/ASPG_intro_2x-42820f33ddc20c7e24e3c17a5647ae00.png"},488:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/multiroute_output_2x-7953a776987f257ef97886c1cffe0589.png"},489:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/background_modes_2x-20210124120826952-1549c4102c0f9b9accd1b1b250fabd1f.png"},490:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/competing_audio_demands_2x-b92e46cee5f9881ca669801886229d61.png"},491:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/audio_session_interrupted_2x-d0af3bb5ddee5d1d4b1068c70f85f808.png"},492:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/audio_route_change_2x-ae28cb4a7d4d66c5f4d5355e335ffc85.png"},493:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/image-20210124171039521-753c2ea6e79ddeb2d17e8198790c9c02.png"},494:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/image-20210124210614014-dc566e2a74a6865d75344d12eebeabf1.png"},495:function(e,t,o){"use strict";o.r(t),t.default=o.p+"assets/images/image-20210124210657041-303358266e6e532ebba85d43db88fb71.png"}}]);