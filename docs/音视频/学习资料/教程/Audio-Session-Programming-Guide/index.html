<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.70">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="My Site Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="My Site Blog Atom Feed"><title data-react-helmet="true">Audio-Session-Programming-Guide | My Site</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Audio-Session-Programming-Guide | My Site"><meta data-react-helmet="true" name="description" content="Audio Session Programming Guide"><meta data-react-helmet="true" property="og:description" content="Audio Session Programming Guide"><meta data-react-helmet="true" property="og:url" content="https://your-docusaurus-test-site.com/docs/音视频/学习资料/教程/Audio-Session-Programming-Guide"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://your-docusaurus-test-site.com/docs/音视频/学习资料/教程/Audio-Session-Programming-Guide"><link rel="stylesheet" href="/styles.8cfbcdec.css">
<link rel="preload" href="/styles.9888532b.js" as="script">
<link rel="preload" href="/runtime~main.73fb2e0e.js" as="script">
<link rel="preload" href="/main.a2e30791.js" as="script">
<link rel="preload" href="/1.fa235d9f.js" as="script">
<link rel="preload" href="/2.8423217f.js" as="script">
<link rel="preload" href="/257.8905f2ed.js" as="script">
<link rel="preload" href="/258.3860215e.js" as="script">
<link rel="preload" href="/935f2afb.ce536a1e.js" as="script">
<link rel="preload" href="/17896441.d8a5f7af.js" as="script">
<link rel="preload" href="/2bccc580.d3084068.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav aria-label="Skip navigation links"><button type="button" tabindex="0" class="skipToContent_11B0">Skip to main content</button></nav><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_YANc themedImage--light_3CMI navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_YANc themedImage--dark_3ARp navbar__logo"><strong class="navbar__title">My Site</strong></a><a class="navbar__item navbar__link" href="/docs/编程基础/编程基础/编程基础">编程基础</a><a class="navbar__item navbar__link" href="/docs/编程语言/编程语言">编程语言</a><a class="navbar__item navbar__link" href="/docs/工具/常用工具">工具</a><a class="navbar__item navbar__link" href="/docs/应用开发/应用开发">应用开发</a><a class="navbar__item navbar__link" href="/docs/Apple/iOS开发/iOS开发">Apple</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/音视频/音视频">音视频</a><a class="navbar__item navbar__link" href="/docs/项目/项目">项目</a></div><div class="navbar__items navbar__items--right"><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2N3Q"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_3NWk">🌜</span></div><div class="react-toggle-track-x"><span class="toggle_3NWk">🌞</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Search" aria-label="Search" class="navbar__search-input search-bar"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_YANc themedImage--light_3CMI navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_YANc themedImage--dark_3ARp navbar__logo"><strong class="navbar__title">My Site</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/docs/编程基础/编程基础/编程基础">编程基础</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/编程语言/编程语言">编程语言</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/工具/常用工具">工具</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/应用开发/应用开发">应用开发</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/Apple/iOS开发/iOS开发">Apple</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/docs/音视频/音视频">音视频</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/项目/项目">项目</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_vMrn"><main class="docMainContainer_2iGs"><div class="container padding-vert--lg docItemWrapper_1bxp"><div class="row"><div class="col docItemCol_U38p"><div class="docItemContainer_a7m4"><article><header><h1 class="docTitle_Oumm">Audio-Session-Programming-Guide</h1></header><div class="markdown"><h1><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-session-programming-guide"></a>Audio Session Programming Guide<a class="hash-link" href="#audio-session-programming-guide" title="Direct link to heading">#</a></h1><p>[toc]</p><p>Audio is a managed service in iOS, tvOS, and watchOS. The system manages audio behavior at the app, inter-app, and device levels through the use of <em>audio sessions</em>.</p><blockquote><p>managed service 托管服务</p><p>through the use of <em>audio sessions</em>. 通过使用 audio session</p></blockquote><p><img alt="../Art/ASPG_intro_2x.png" src="/assets/images/ASPG_intro_2x-42820f33ddc20c7e24e3c17a5647ae00.png"></p><p>You use an audio session to communicate to the system how you intend to use audio in your app. This audio session acts as an intermediary between your app and the operating system—and in turn, the underlying audio hardware. You use it to communicate to the operating system the nature of your app’s audio without detailing the specific behavior or required interactions with the audio hardware. Delegating the management of those details to the audio session ensures optimal management of the user’s audio experience.</p><blockquote><p>the nature of your app’s audio  应用程序音频的性质</p><p>optimal management of the user’s audio experience. 用户的音频体验到的最佳管理</p></blockquote><p><strong>At a Glance</strong></p><p>You interact with your app’s audio session using an instance of <code>AVAudioSession</code> to:</p><ul><li>Configure the audio session category and mode to communicate to the system how you intend to use audio in your app</li><li>Activate your app’s audio session to put your category and mode configuration into action</li><li>Subscribe and respond to important audio session notifications, such as audio interruptions and route changes</li><li>Perform advanced audio device configuration such as setting sample rate, I/O buffer duration, and number of channels</li></ul><p><strong>An Audio Session Manages Audio Behavior</strong></p><p>An <em>audio session</em> is the intermediary between your app and the operating system that is used to configure your app’s audio behavior. Upon launch, your app is automatically provided with a singleton audio session. You configure it to provide the desired behavior and activate it to put that behavior into action.</p><blockquote><p><strong>Relevant Chapters:</strong> <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/ConfiguringanAudioSession/ConfiguringanAudioSession.html#//apple_ref/doc/uid/TP40007875-CH2-SW1" target="_blank" rel="noopener noreferrer">Activating an Audio Session</a>.</p></blockquote><p><strong>Categories Express Audio Roles</strong></p><p>The primary mechanism for expressing audio behaviors is the audio session category. By setting the category, you indicate whether your app uses input or output routes, whether you want music to continue playing along with your audio, and so on. The behavior you specify should meet user expectations as described in <a href="https://developer.apple.com/ios/human-interface-guidelines/interaction/audio/" target="_blank" rel="noopener noreferrer">Audio</a> in <em>iOS Human Interface Guidelines</em>.</p><blockquote><p>expressing audio behaviors 表达音频行为</p><p>The primary mechanism： 主要机制</p></blockquote><p>AVFoundation defines a number of audio session categories, along with a set of override and modifier switches, that let you customize audio behavior according to your app’s personality or role.</p><blockquote><p>along with 以及</p><p> a set of override and modifier switches 一组替代和修饰符开关</p><p> customize audio behavior 自定义音频行为</p></blockquote><p>Various categories support playback, recording, and playback with recording. When the system knows your app’s audio role, it provides you appropriate access to hardware resources. The system also ensures that other audio on the device behaves in a way that works for your app and is consistent with user expectations.</p><blockquote><p> is consistent with 符合</p></blockquote><p>Some categories can further be customized by specifying a mode, which is used to specialize the behavior of a given category. For example, when an app uses Video Recording mode, the system might choose a different built-in microphone than it would choose if it were using the default mode. The system might also engage microphone signal processing that is tuned for video recording use cases.</p><blockquote><p>engage microphone signal processing   调整 microphone signal processing </p><p> tuned for video recording use cases. 针对录像用例进行调整</p></blockquote><blockquote><p><strong>Relevant Chapters:</strong> <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionBasics/AudioSessionBasics.html#//apple_ref/doc/uid/TP40007875-CH3-SW1" target="_blank" rel="noopener noreferrer">Configuring an Audio Session</a>.</p></blockquote><p><strong>Notifications Support Interruption Handling</strong></p><p>An <em>audio interruption</em> is the deactivation of your app’s audio session—which immediately stops your audio. Interruptions occur when a competing audio session from an app is activated and that session is not categorized by the system to mix with yours. Your app should respond to interruptions by saving state, updating the user interface, and so on. To be notified when audio interruptions begin and end, register to observe notifications of type <code>AVAudioSessionInterruptionNotification</code>.</p><blockquote><p> categorized by the system to mix with yours. 系统归类于您的会话混合</p></blockquote><blockquote><p><strong>Relevant Chapters:</strong> <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/HandlingAudioInterruptions/HandlingAudioInterruptions.html#//apple_ref/doc/uid/TP40007875-CH4-SW1" target="_blank" rel="noopener noreferrer">Responding to Interruptions</a>.</p></blockquote><p><strong>otifications Support Audio Route Change Handling</strong></p><p>Users have particular expectations when they initiate an <em>audio route change</em> by docking or undocking a device, or by plugging in or unplugging a headset. <em>iOS Human Interface Guidelines</em> describes these expectations and provides guidelines on how to meet them. Handle route changes by registering to observe notifications of type <code>AVAudioSessionRouteChangeNotification</code>.</p><blockquote><p>particular expectations 特别的期待 </p><p>docking 码头，靠岸，对接</p><p>undocking 离开码头，断开连接</p></blockquote><blockquote><p><strong>Relevant Chapters:</strong> <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/HandlingAudioHardwareRouteChanges/HandlingAudioHardwareRouteChanges.html#//apple_ref/doc/uid/TP40007875-CH5-SW1" target="_blank" rel="noopener noreferrer">Responding to Route Changes</a>.</p></blockquote><p><strong>Audio Sessions Control Device Configuration</strong></p><p>Apps don’t have direct control over device hardware, but an audio session provides the interface for you to request your <em>preferred</em> hardware device settings. This interface enables you to perform advanced audio device configuration such as setting sample rate, I/O buffer duration, and number of audio channels.</p><blockquote><p><strong>Relevant Chapters:</strong> <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/OptimizingForDeviceHardware/OptimizingForDeviceHardware.html#//apple_ref/doc/uid/TP40007875-CH6-SW1" target="_blank" rel="noopener noreferrer">Configuring Device Hardware</a>.</p></blockquote><p><strong>Audio Sessions Protect User Privacy</strong></p><p>Apps that record audio, alone or in conjunction with video, require explicit user permission before recording is allowed. Until the user grants your app permission to record, the app can record only silence. <code>AVAudioSession</code> provides the interface to ask for this permission and determine the user’s privacy setting.</p><blockquote><p>determine ： 决定，确定 </p><p>determine the user’s privacy setting. 确定用户的隐私设置</p></blockquote><p><strong>Prerequisites</strong></p><blockquote><p>预备知识</p></blockquote><p>Be familiar with Cocoa Touch development as introduced in <em><a href="https://developer.apple.com/library/archive/documentation/iPhone/Conceptual/iPhoneOSProgrammingGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40007072" target="_blank" rel="noopener noreferrer">App Programming Guide for iOS</a></em> and with the basics of Core Audio as described in that document and in <em><a href="https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/Introduction/Introduction.html#//apple_ref/doc/uid/TP40003577" target="_blank" rel="noopener noreferrer">Core Audio Overview</a></em>. Because audio sessions bear on practical end-user scenarios, also be familiar with iOS devices and with iOS Human Interface Guidelines, especially the <a href="https://developer.apple.com/ios/human-interface-guidelines/interaction/audio/" target="_blank" rel="noopener noreferrer">Audio</a> section in <em>iOS Human Interface Guidelines</em>.</p><blockquote><p>especially the Audio section in iOS Human Interface Guidelines. 特别是人际交互指南的音频部分</p></blockquote><p><a href="https://developer.apple.com/design/human-interface-guidelines/ios/user-interaction/audio/" target="_blank" rel="noopener noreferrer">https://developer.apple.com/design/human-interface-guidelines/ios/user-interaction/audio/</a></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="configuring--an-audio-session"></a>Configuring  an Audio Session<a class="hash-link" href="#configuring--an-audio-session" title="Direct link to heading">#</a></h2><p>An audio session category is a key that identifies a set of audio behaviors for your app. By setting a category, you indicate your audio intentions to the system—such as whether your audio should continue when the Ringer/Silent switch is flipped. Several audio session categories, along with a set of override and modifier switches, let you customize your app’s audio behavior.</p><blockquote><p>when the Ringer/Silent switch is flipped. 当振铃/静音开关被拨动的时候</p><p>Several audio session categories 多个音频会话类别</p><p> along with 以及</p><p>override and modifier switches 替代和修饰符开关</p><p>customize your app’s audio behavior. 自定义音频的行为</p></blockquote><p>As detailed in <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionCategoriesandModes/AudioSessionCategoriesandModes.html#//apple_ref/doc/uid/TP40007875-CH10-SW3" target="_blank" rel="noopener noreferrer">Table B-1</a>, each audio session category specifies a particular set of responses to each of the following behaviors:</p><ul><li><em>Interrupts nonmixable apps audio:</em> If yes, nonmixable apps are interrupted when your app activates its audio session.</li><li><em>Silenced by the Silent switch:</em> If yes, your audio is silenced when the user activates the Silent switch. (On iPhone, this switch is called the <em>Ring/Silent switch</em>.)</li><li><em>Supports audio input:</em> If yes, app audio input (recording) is allowed.</li><li><em>Supports audio output:</em> If yes, app audio output (playback) is allowed.</li></ul><p>Most apps only need to set the category once, at launch, but you can change the category as often as you need to. You can change it while the audio session is active; however, it’s generally preferable to deactivate your audio session before changing the category or other session properties. Making these changes while the session is deactivated prevents unnecessary reconfigurations of the audio system.</p><blockquote><p>it’s generally preferable to 通常最好</p><p>deactivate your audio session 停用你的audio session</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-session-default-behavior"></a>Audio Session Default Behavior<a class="hash-link" href="#audio-session-default-behavior" title="Direct link to heading">#</a></h3><p>All iOS, tvOS, and watchOS apps have a default audio session that is preconfigured as follows:</p><ul><li>Audio playback is supported, but audio recording is disallowed.</li><li>In iOS, setting the Ring/Silent switch to silent mode silences any audio being played by the app.</li><li>In iOS, when the device is locked, the app&#x27;s audio is silenced.</li><li>When your app plays audio, any other background audio—such as audio being played by the Music app—is silenced.</li></ul><p>The default audio session has useful behavior, but in most cases, you should customize it to better suit your app’s needs. To change the behavior, you configure your app’s audio session.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="configuring-your-audio-session"></a>Configuring Your Audio Session<a class="hash-link" href="#configuring-your-audio-session" title="Direct link to heading">#</a></h3><p>The primary means of configuring your audio session is by setting its category. An audio session category defines a set of audio behaviors. The precise behaviors associated with each category are not under your app’s control, but rather are set by the operating system. Apple may refine category behavior in future versions of the OS, so your best strategy is to pick the category that most accurately describes your intentions for the audio behavior you want. <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionCategoriesandModes/AudioSessionCategoriesandModes.html#//apple_ref/doc/uid/TP40007875-CH10-SW1" target="_blank" rel="noopener noreferrer">Audio Session Categories and Modes</a> summarizes behavior details for each category.</p><blockquote><p> most accurately describes 最精准的描述</p></blockquote><p>While categories set the base audio behaviors for your app, you can further specialize those behaviors by setting the category’s mode. For instance, a Voice over IP (VoIP) app would use <code>AVAudioSessionCategoryPlayAndRecord</code>. You can specialize the behavior of this category for a VoIP app by setting the audio session’s mode to <code>AVAudioSessionModeVoiceChat</code>. This mode ensures that signals are optimized for voice through system-supplied signal processing.</p><p>Certain categories support overriding their default behavior by setting one or more category options on the session (see <code>AVAudioSessionCategoryOptions</code>). For instance, the default behavior associated with the <code>AVAudioSessionCategoryPlayback</code> category interrupts other system audio when the session is activated. In most cases, a playback app needs this behavior. However, if you want your audio to mix with other system audio, you can override this behavior by setting the <code>AVAudioSessionCategoryOptionMixWithOthers</code> option on the session.</p><p>To set the audio session category (and optionally its mode and options), call the <code>setCategory:mode:options:error:</code> method as shown in Listing 1-1.</p><p><strong>Listing 1-1</strong> Setting the audio session category using the AVFoundation framework</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-c codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic">// Access the shared, singleton audio session instance</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">let session </span><span class="token operator" style="color:rgb(137, 221, 255)">=</span><span class="token plain"> AVAudioSession</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token function" style="color:rgb(130, 170, 255)">sharedInstance</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token keyword" style="font-style:italic">do</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token comment" style="color:rgb(105, 112, 152);font-style:italic">// Configure the audio session for movie playback</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try session</span><span class="token punctuation" style="color:rgb(199, 146, 234)">.</span><span class="token function" style="color:rgb(130, 170, 255)">setCategory</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token plain">AVAudioSessionCategoryPlayback</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                            mode</span><span class="token operator" style="color:rgb(137, 221, 255)">:</span><span class="token plain"> AVAudioSessionModeMoviePlayback</span><span class="token punctuation" style="color:rgb(199, 146, 234)">,</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                            options</span><span class="token operator" style="color:rgb(137, 221, 255)">:</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(199, 146, 234)">[</span><span class="token punctuation" style="color:rgb(199, 146, 234)">]</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span><span class="token plain"> catch let error as NSError </span><span class="token punctuation" style="color:rgb(199, 146, 234)">{</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    </span><span class="token function" style="color:rgb(130, 170, 255)">print</span><span class="token punctuation" style="color:rgb(199, 146, 234)">(</span><span class="token string" style="color:rgb(195, 232, 141)">&quot;Failed to set the audio session category and mode: \(error.localizedDescription)&quot;</span><span class="token punctuation" style="color:rgb(199, 146, 234)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"></span><span class="token punctuation" style="color:rgb(199, 146, 234)">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="expanding-options-using-the-multiroute-category"></a>Expanding Options Using the Multiroute Category<a class="hash-link" href="#expanding-options-using-the-multiroute-category" title="Direct link to heading">#</a></h3><p>The multiroute category works slightly differently from the other categories. All other categories follow the “last in wins” rule, where the last device plugged into an input or output route is the dominant device. However, the multiroute category enables the app to use all of the connected output ports instead of only the last-in port. For example, if you are listening to audio through the HDMI output route and plug in a set of headphones, your app continues playing audio through the HDMI output route while also playing audio through the headphones.</p><blockquote><p>slightly differently from 稍微不同</p></blockquote><p>With the multiroute category, your app can also send different audio streams to different output routes. For example, your app can send one audio stream to the left headphone, another to the right headphone, and a third to the HDMI routes. Figure 1-1 shows an example of sending multiple audio streams to different audio routes.</p><p><strong>Figure 1-1</strong> Sending different audio streams to different audio routes</p><p><img alt="img" src="/assets/images/multiroute_output_2x-7953a776987f257ef97886c1cffe0589.png"></p><p>Depending on the device and any connected accessories, the following are valid output route combinations:</p><ul><li>USB and headphones</li><li>HDMI and headphones</li><li>LineOut and headphones</li></ul><blockquote><p>Depending on 根据</p><p>valid output route combinations ：有效的输出路由组合</p></blockquote><p>The multiroute category supports the use of a single input port.</p><p><strong>Important:</strong> The built-in speaker may be used only if no other eligible output ports (USB, HDMI, LineOut) are connected.</p><blockquote><p>no other eligible output ports 没有其他合适的输出端口</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="chooseing-categores-and-modes-for-airplay"></a>Chooseing Categores and Modes for Airplay<a class="hash-link" href="#chooseing-categores-and-modes-for-airplay" title="Direct link to heading">#</a></h3><p>Only specific categories and modes support AirPlay. The following categories support both the mirrored and non-mirrored versions of AirPlay:</p><ul><li><code>AVAudioSessionCategorySoloAmbient</code></li><li><code>AVAudioSessionCategoryAmbient</code></li><li><code>AVAudioSessionCategoryPlayback</code></li></ul><p>The <code>AVAudioSessionCategoryPlayAndRecord</code> category and the following modes support only the mirrored version of AirPlay:</p><ul><li><code>AVAudioSessionModeDefault</code></li><li><code>AVAudioSessionModeVideoChat</code></li><li><code>AVAudioSessionModeGameChat</code></li></ul><p><strong>Note:</strong> Starting in iOS 10, you can enable non-mirrored AirPlay output when using the <code>AVAudioSessionCategoryPlayAndRecord</code> category by activating your session with the <code>AVAudioSessionCategoryOptionAllowAirPlay</code> option.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="enabling-background-audio"></a>Enabling background Audio<a class="hash-link" href="#enabling-background-audio" title="Direct link to heading">#</a></h3><p>iOS and tvOS apps require you to enable certain capabilities for some background operations. A common capability required by playback apps is to play background audio. With this capability enabled, your app’s audio can continue when users switch to another app or when they lock their iOS devices. This capability is also required for enabling advanced playback features like AirPlay streaming and Picture in Picture playback in iOS.</p><p>The simplest way to configure these capabilities is by using Xcode. Select your app’s target in Xcode and select the Capabilities tab. Under the Capabilities tab, set the Background Modes switch to ON and select the “Audio, AirPlay, and Picture in Picture” option from the list of available modes.</p><p><img alt="../Art/background_modes.shot/Resources/shot_2x.png" src="/assets/images/background_modes_2x-20210124120826952-1549c4102c0f9b9accd1b1b250fabd1f.png"></p><p>With this background mode enabled and your audio session configured with an appropriate category, your app is ready to play background audio.</p><p><strong>Note:</strong> To allow the audio portion of a video presentation to play in the background, see <a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MediaPlaybackGuide/Contents/Resources/en.lproj/RefiningTheUserExperience/RefiningTheUserExperience.html#//apple_ref/doc/uid/TP40016757-CH6-SW9" target="_blank" rel="noopener noreferrer">Playing Background Audio</a> in <em><a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/MediaPlaybackGuide/Contents/Resources/en.lproj/Introduction/Introduction.html#//apple_ref/doc/uid/TP40016757" target="_blank" rel="noopener noreferrer">Media Playback Programming Guide</a></em>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="activating-an-audio-session"></a>Activating an Audio Session<a class="hash-link" href="#activating-an-audio-session" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="how-the-system-resolves-competing-audio-demands"></a>How the System Resolves Competing Audio Demands<a class="hash-link" href="#how-the-system-resolves-competing-audio-demands" title="Direct link to heading">#</a></h3><blockquote><p>系统如何解决竞争音频的需求 （Competing Audio Demands）</p></blockquote><p>As your app launches, built-in apps (Messages, Music, Safari, the phone) may be running in the background. Each of these may produce audio: a text message arrives, a podcast you started 10 minutes ago continues playing, and so on.</p><p>If you think of a device as an airport, with apps represented as taxiing airplanes, the system serves as a sort of control tower. Your app can make audio requests and state its desired priority, but final authority over what happens “on the tarmac” comes from the system. You communicate with the “control tower” using the audio session. Figure 2-1 illustrates a typical scenario—your app asking to use audio while the Music app is already playing. In this scenario, your app interrupts the Music app.</p><p><strong>Figure 2-1</strong> The system manages competing audio demands</p><p><img alt="A comic-book representation of the sequence of events surrounding the activation of an audio session." src="/assets/images/competing_audio_demands_2x-b92e46cee5f9881ca669801886229d61.png"></p><blockquote><p> state its desired priority,声明他所需要的优先级</p><p> final authority over 最终决定，控制</p></blockquote><p>In step 1 of the figure, your app requests activation of its audio session. You’d make such a request, for example, on app launch, or perhaps in response to a user tapping the Play button in an audio recording and playback app. In step 2, the system considers the activation request. Specifically, it considers the category you’ve assigned to your audio session. In Figure 2-1, your app uses a category that requires other audio to be silenced.</p><p>In steps 3 and 4, the system deactivates the Music app’s audio session, stopping its audio playback. Finally, in step 5, the system activates your app’s audio session and playback can begin.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="activity-and-deactivaty-you-audio-session"></a>Activity and Deactivaty you Audio Session<a class="hash-link" href="#activity-and-deactivaty-you-audio-session" title="Direct link to heading">#</a></h3><p>Although the AVFoundation playback and recording classes automatically activate your audio session, manually activating it gives you an opportunity to test whether activation succeeded. However, if your app has a play/pause UI element, write your code so that the user must press Play before the session is activated. Likewise, when changing your audio session’s active/inactive state, check to ensure that the call is successful. Write your code to gracefully handle the system’s refusal to activate your session.</p><blockquote><p>gracefully handle 妥善处理</p><p>refusal to activate your session. 拒绝激活你的session</p></blockquote><p>The system deactivates your audio session for a Clock or Calendar alarm or an incoming phone call. When the user dismisses the alarm, or chooses to ignore a phone call, the system allows your session to become active again. Whether to reactivate a session at the end of an interruption depends on the app type, as described in <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioGuidelinesByAppType/AudioGuidelinesByAppType.html#//apple_ref/doc/uid/TP40007875-CH11-SW1" target="_blank" rel="noopener noreferrer">Audio Guidelines By App Type</a>.</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">let session = AVAudioSession.sharedInstance()</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">do {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    // 1) Configure your audio session category, options, and mode</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    // 2) Activate your audio session to enable your custom configuration</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try session.setActive(true)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">} catch let error as NSError {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Unable to activate audio session:  \(error.localizedDescription)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>To deactivate your audio session, pass <code>false</code> to the <code>setActive</code> method.</p><p>When playing or recording audio with an AVFoundation object (<code>AVPlayer</code>, <code>AVAudioRecorder</code>, and so on), the system takes care of audio session reactivation upon interruption end. However, if you register for notification messages and explicitly reactivate your audio session, you can verify that reactivation succeeded, and you can update your app’s state and user interface. For more information, see <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/HandlingAudioInterruptions/HandlingAudioInterruptions.html#//apple_ref/doc/uid/TP40007875-CH4-SW6" target="_blank" rel="noopener noreferrer">Figure 3-1</a>.</p><p>Many apps never need to deactivate their audio session explicitly. Important exceptions include VoIP apps, turn-by-turn navigation apps, and, in some cases, playback and recording apps.</p><ul><li>Ensure that the audio session for a VoIP app, which usually runs in the background, is active only while the app is handling a call. In the background, standing ready to receive a call, a VoIP app’s audio session should not be active.</li><li>Ensure that the audio session for an app using a recording category is active only while recording. Before recording starts and when it stops, ensure that your session is inactive to allow other sounds, such as incoming message alerts, to play.</li><li>If an app supports background audio playback or recording, deactivate its audio session when entering the background if the app is not actively using audio (or preparing to use audio). Doing so allows the system to free up audio resources so that they may be used by other processes. It also prevents the app&#x27;s audio session from being deactivated when the app process is suspended by the operating system (see <code>AVAudioSessionInterruptionWasSuspendedKey</code>).</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="checking-whether-other-audio-is-playing"></a>Checking Whether Other Audio is Playing<a class="hash-link" href="#checking-whether-other-audio-is-playing" title="Direct link to heading">#</a></h3><p>When your app becomes active, sound may already be playing on the device. For example, the Music app may be playing a song when a user launches your app, or Safari may be streaming audio. Knowing if other audio is playing is especially important if your app is a game. Many games have a music sound track as well as sound effects. <a href="https://developer.apple.com/ios/human-interface-guidelines/interaction/audio/" target="_blank" rel="noopener noreferrer">Audio</a> in <em>iOS Human Interface Guidelines</em> advises you to assume that users expect the other audio to continue, along with the game’s sound effects, as they play the game.</p><p>In your app delegate’s <code>applicationDidBecomeActive:</code> method, inspect the audio session’s <code>secondaryAudioShouldBeSilencedHint</code> property to determine if audio is already playing. The value is <code>true</code> when another app with a nonmixable audio session is playing audio. Apps should use this property as a hint to silence audio that is secondary to the functioning of the app. For example, a game using <code>AVAudioSessionCategoryAmbient</code> can use this property to determine if it should mute its soundtrack while leaving its sound effects unmuted.</p><p>You can also subscribe to notifications of type <code>AVAudioSessionSilenceSecondaryAudioHintNotification</code> to ensure that your app is notified when optional secondary audio muting should begin or end. This notification is sent only to registered listeners who are currently in the foreground and have an active audio session.</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">func setupNotifications() {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    NotificationCenter.default.addObserver(self,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           selector: #selector(handleSecondaryAudio),</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           name: .AVAudioSessionSilenceSecondaryAudioHint,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           object: AVAudioSession.sharedInstance())</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">func handleSecondaryAudio(notification: Notification) {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    // Determine hint type</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    guard let userInfo = notification.userInfo,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let typeValue = userInfo[AVAudioSessionSilenceSecondaryAudioHintTypeKey] as? UInt,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let type = AVAudioSessionSilenceSecondaryAudioHintType(rawValue: typeValue) else {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            return</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    if type == .begin {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // Other app audio started playing - mute secondary audio</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    } else {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // Other app audio stopped playing - restart secondary audio</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>This notification&#x27;s <code>userInfo</code> dictionary contains an <code>AVAudioSessionSilenceSecondaryAudioHintType</code> value for <code>AVAudioSessionSilenceSecondaryAudioHintTypeKey</code>. Use the audio hint type to determine if your secondary audio muting should begin or end.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="responding-to-interruptions"></a>Responding to interruptions<a class="hash-link" href="#responding-to-interruptions" title="Direct link to heading">#</a></h2><p>Adding audio session code to handle interruptions ensures that your app’s audio continues behaving gracefully when a phone call arrives, a Clock or Calendar alarm sounds, or another app activates its audio session.</p><p>An <em>audio interruption</em> is the deactivation of your app’s audio session—which immediately stops your audio. Interruptions happen when a competing audio session from an app is activated and that session is not categorized by the system to mix with yours. After your session goes inactive, the system sends a “you were interrupted” message that you can respond to by saving state, updating the user interface, and so on.</p><p>Your app may be suspended following an interruption. This happens when a user accepts a phone call. If a user instead ignores a call, or dismisses an alarm, the system issues an “interruption ended” message, and your app continues running. For your audio to resume, you must reactivate your audio session.</p><blockquote><p>For your audio to resume, you must reactivate your audio session. 要恢复audio 必须重新激活session</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="the-interruption-life-cycle"></a>The Interruption Life Cycle<a class="hash-link" href="#the-interruption-life-cycle" title="Direct link to heading">#</a></h3><p>Figure 3-1 illustrates the sequence of events before, during, and after an audio session interruption for a playback app.</p><p><strong>Figure 3-1</strong> An audio session is interrupted<img alt="A timeline representation of an application&amp;#39;s audio session getting interrupted by a phone call." src="/assets/images/audio_session_interrupted_2x-d0af3bb5ddee5d1d4b1068c70f85f808.png"></p><p>An interruption event—in this example, the arrival of a FaceTime request—proceeds as follows. The numbered steps correspond to the numbers in the figure.</p><blockquote><p>proceeds as follows 发生如下事件</p><p>correspond to 符合对应</p></blockquote><p>An interruption event—in this example, the arrival of a FaceTime request—proceeds as follows. The numbered steps correspond to the numbers in the figure.</p><ol><li>Your app is active, playing back audio.</li><li>A FaceTime request arrives. The system activates the FaceTime app’s audio session.</li><li>The system deactivates your audio session. At this point, playback in your app has stopped.</li><li>The system posts a notification, indicating that your session has been deactivated.</li><li>Your notification handler takes appropriate action. For example, it could update the user interface and save the information needed to resume playback at the point where it stopped.</li><li>If the user dismisses the interruption—ignoring the incoming FaceTime request—the system posts a notification, indicating that the interruption has ended.</li><li>Your notification handler takes action appropriate to the end of an interruption. For example, it might update the user interface, reactivate the audio session, and resume playback.</li><li>(Not shown in the figure.) If, instead of dismissing the interruption at step 6, the user accepts a phone call, your app is suspended.</li></ol><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-interruption-handling-techniques"></a>Audio Interruption handling Techniques<a class="hash-link" href="#audio-interruption-handling-techniques" title="Direct link to heading">#</a></h3><p>Handle interruptions by registering to observe interruption notifications posted by <code>AVAudioSession</code>. What you do within your interruption code depends on the audio technology you are using and on what you are using it for—playback, recording, audio format conversion, reading streamed audio packets, and so on. Generally speaking, you need to ensure the minimum possible disruption, and the most graceful possible recovery, from the perspective of the user.</p><p>Table 3-1 summarizes appropriate audio session behavior during an interruption. If you use AVFoundation playback or recording objects, some of these steps are handled automatically by the system.</p><table><thead><tr><th><em>After interruption starts</em></th><th>Save state and contextUpdate user interface</th></tr></thead><tbody><tr><td><em>After interruption ends</em></td><td>Restore state and contextUpdate user interfaceReactivate audio session, if appropriate for the app</td></tr></tbody></table><p>Table 3-2 summarizes how to handle audio interruptions according to technology. The rest of this chapter provides details.</p><table><thead><tr><th align="left">Audio technology</th><th align="left">How interruptions work</th></tr></thead><tbody><tr><td align="left">AVFoundation framework</td><td align="left">The system automatically pauses playback or recording upon interruption and reactivates your audio session when you resume playback or recording.If you want to save and restore the playback position between app launches, save the playback position on interruption as well as on app quit.</td></tr><tr><td align="left">Audio Queue Services, I/O audio unit</td><td align="left">These technologies put your app in control of handling interruptions. You are responsible for saving playback or recording position and for reactivating your audio session after the interruption ends.</td></tr><tr><td align="left">System Sound Services</td><td align="left">Sounds played using System Sound Services go silent when an interruption starts. The sounds are eligible to be played again if the interruption ends. Apps cannot influence the interruption behavior for sounds that use this playback technology.</td></tr></tbody></table><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="handling-interruption-from-siri"></a>Handling Interruption from Siri<a class="hash-link" href="#handling-interruption-from-siri" title="Direct link to heading">#</a></h3><p>When Siri interrupts your app’s playback, you must keep track of any remote control commands issued by Siri while the audio session is in an interrupted state. During the interruption, keep track of any commands issued by Siri and respond accordingly when the interruption ends. For example, during the interruption, the user asks Siri to pause your app’s audio playback. When your app is notified that the interruption has ended, it should not automatically resume playing. Instead, your app’s UI should indicate that the app is in a paused state.</p><blockquote><p>you must keep track of any remote control commands issued by Siri 跟踪siri发出的命令</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="observer-audio-interruptions"></a>Observer Audio Interruptions<a class="hash-link" href="#observer-audio-interruptions" title="Direct link to heading">#</a></h3><p>To handle audio interruptions, begin by registering to observe notifications of type AVAudioSessionInterruptionNotification.</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">func registerForNotifications() {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    NotificationCenter.default.addObserver(self,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           selector: #selector(handleInterruption),</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           name: .AVAudioSessionInterruption,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           object: AVAudioSession.sharedInstance())</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">func handleInterruption(_ notification: Notification) {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    // Handle interruption</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>The posted <code>NSNotification</code> instance contains a populated <code>userInfo</code> dictionary providing the details of the interruption. You determine the type of interruption by retrieving the <code>AVAudioSessionInterruptionType</code> value from the <code>userInfo</code> dictionary. The interruption type indicates whether the interruption has begun or has ended.</p><blockquote><p>a populated <code>userInfo</code> dictionary 一个填充的userinfo 字典</p><p>You determine the type of interruption 你需要确定中断的类型</p><p>by retrieving the <code>AVAudioSessionInterruptionType</code> value from the <code>userInfo</code> dictionary 通过检索AVAudioSessionInterruptionType 的值</p><p>The interruption type indicates whether the interruption has begun or has ended. 中断类型指示，中断是开始还是结束</p></blockquote><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">func handleInterruption(_ notification: Notification) {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    guard let info = notification.userInfo,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let typeValue = info[AVAudioSessionInterruptionTypeKey] as? UInt,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let type = AVAudioSessionInterruptionType(rawValue: typeValue) else {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            return</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    if type == .began {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // Interruption began, take appropriate actions (save state, update user interface)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    else if type == .ended {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        guard let optionsValue =</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            userInfo[AVAudioSessionInterruptionOptionKey] as? UInt else {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                return</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let options = AVAudioSessionInterruptionOptions(rawValue: optionsValue)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        if options.contains(.shouldResume) {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            // Interruption Ended - playback should resume</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>If the interruption type is <code>AVAudioSessionInterruptionTypeEnded</code>, the <code>userInfo</code> dictionary might contain an <code>AVAudioSessionInterruptionOptions</code> value. An options value of <code>AVAudioSessionInterruptionOptionShouldResume</code> is a hint that indicates whether your app should automatically resume playback if it had been playing when it was interrupted. Media playback apps should always look for this flag before beginning playback after an interruption. If it’s not present, playback should not begin again until initiated by the user. Apps that don’t present a playback interface, such as a game, can ignore this flag and reactivate and resume playback when the interruption ends.</p><blockquote><p>Media playback apps 媒体播放app</p><p>should always look for this flag 应该寻找此标识</p><p> If it’s not present, playback should not begin again until initiated by the user. 如果不存在，则在用户播放之前不应重新快开始播放。</p><p>Apps that don’t present a playback interface 未提供播放界面的APP</p></blockquote><p><strong>Note:</strong> There is no guarantee that a begin interruption will have a corresponding end interruption. Your app needs to be aware of a switch to a foreground running state or the user pressing a Play button. In either case, determine whether your app should reactivate its audio session.</p><blockquote><p>There is no guarantee that a begin interruption will have a corresponding end interruption.  不保证，开始中断会产生相应定的结束中断</p><p>be aware of 需要知道</p><p>In either case 无论哪种情况</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="responding--to-a-media-server-reset"></a>Responding  to a media server Reset<a class="hash-link" href="#responding--to-a-media-server-reset" title="Direct link to heading">#</a></h3><p>The media server provides audio and other multimedia functionality through a shared server process. Although rare, it’s possible for the media server to reset while your app is active. Register for the <code>AVAudioSessionMediaServicesWereResetNotification</code> notification to monitor for a media server reset. After receiving the notification, your app needs to do the following:</p><ul><li>Dispose of orphaned audio objects (such as players, recorders, converters, or audio queues) and create new ones</li><li>Reset any internal audio states being tracked, including all properties of <code>AVAudioSession</code></li><li>When appropriate, reactivate the <code>AVAudioSession</code> instance using the <code>setActive:error:</code> method</li></ul><p><strong>Important:</strong> Apps do not need to re-register for any <code>AVAudioSession</code> notifications or reset key-value observers on <code>AVAudioSession</code> properties.</p><p>You can also register for the <code>AVAudioSessionMediaServicesWereLostNotification</code> notification if you want to know when the media server first becomes unavailable. However, most apps only need to respond to the reset notification. Use the lost notification only if the app must respond to user events that occur after the media server is lost, but before the media server is reset.</p><p><strong>Note:</strong> You can trigger a media server crash and restart by choosing Reset Media Services from the Developer menu in Settings. Using this utility makes it easy for you to ensure that your app responds appropriately if media services are reset.</p><blockquote><p>Although rare,  尽管罕见</p></blockquote><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="responding-to-route-changes"></a>Responding to Route Changes<a class="hash-link" href="#responding-to-route-changes" title="Direct link to heading">#</a></h2><p>As your app runs, a user might plug in or unplug a headset, or use a docking station with audio connections.</p><blockquote><p>might plug in or unplug a headset 可能会插入或者拔出耳机，</p><p>or use a docking station with audio connections.  或者使用带有音频连接的扩展坞</p></blockquote><p>To implement the recommendations, write audio session code to handle audio hardware route changes. Certain types of apps, like games, don’t always have to respond to route changes. However, other types of apps, such as media players, must respond to all route changes.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="varieties-of-audio-hardware-route-change"></a>Varieties Of Audio Hardware Route Change<a class="hash-link" href="#varieties-of-audio-hardware-route-change" title="Direct link to heading">#</a></h3><blockquote><p>各种音频硬件路由变化</p></blockquote><p>An audio hardware route is a wired electronic pathway for audio signals.When a user of a device plugs in or unplugs a headset, the system automatically changes the audio hardware route. Your app can be notified of such changes if you register to observe notifications of type AVAudioSessionRouteChangeNotification.</p><blockquote><p>An audio hardware route is a wired electronic pathway for audio signals 音频硬件路由是 音频信号的有线电子路径</p></blockquote><p>Figure 4-1 depicts the sequence of events for various route changes during recording and playback. The four possible outcomes, shown across the bottom of the figure, result from actions taken by a property listener callback function that you write.</p><p><strong>Figure 4-1</strong> Handling audio hardware route changes<img alt="A flowchart representation of how Core Audio, and your property listener callback function, interact to provide good user experience upon an audio hardware route change." src="/assets/images/audio_route_change_2x-ae28cb4a7d4d66c5f4d5355e335ffc85.png"></p><p>As shown in the figure, the system initially determines the audio route after your app launches. It continues to monitor the active route as your app runs. Consider first the case of a user tapping the Record button in your app, represented by the “Recording starts” box on the left side of the figure.</p><p>During recording, the user may plug in or unplug a headset—see the diamond-shaped decision element toward the lower-left of the figure. In response, the system sends a route change notification containing the reason for the change, and the previous route. Your app should stop recording.</p><p>The case for playback is similar but has different outcomes, as shown on the right of the figure. If a user unplugs the headset during playback, your app should pause the audio. If a user plugs in the headset during playback, your app should simply allow playback to continue.</p><blockquote><p> the system initially determines the audio route after your app launches。 APP 启动后系统最初决定音频路由。</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="observering-audio-route-changes"></a>Observering Audio Route Changes<a class="hash-link" href="#observering-audio-route-changes" title="Direct link to heading">#</a></h3><blockquote><p>监听音频路由变化</p></blockquote><p>Audio route changes occur for a number of reasons, including a user plugging in a pair of headphones, connecting a Bluetooth LE headset, or unplugging a USB audio interface. Knowing when these changes occur may be important to your app so you can update its user interface or change its internal state. You can be notified of audio route changes by registering to observe notifications of type <code>AVAudioSessionRouteChangeNotification</code>.</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">func setupNotifications() {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    NotificationCenter.default.addObserver(self,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           selector: #selector(handleRouteChange),</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           name: .AVAudioSessionRouteChange,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                                           object: AVAudioSession.sharedInstance())</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">func handleRouteChange(_ notification: Notification) {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>The posted notification contains a populated <code>userInfo</code> dictionary providing the details of the route change. You can determine the reason for this change by retrieving the <code>AVAudioSessionRouteChangeReason</code> value from the <code>userInfo</code> dictionary. When a new device is connected, the reason is <code>AVAudioSessionRouteChangeReasonNewDeviceAvailable</code>, and when one is removed, it is <code>AVAudioSessionRouteChangeReasonOldDeviceUnavailable</code>.</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">func handleRouteChange(_ notification: Notification) {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    guard let userInfo = notification.userInfo,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let reason = AVAudioSessionRouteChangeReason(rawValue:reasonValue) else {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            return</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    switch reason {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    case .newDeviceAvailable:</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // Handle new device available.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    case .oldDeviceUnavailable:</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // Handle old device removed.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    default: ()</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>When a new device becomes available, you query the audio session’s <code>currentRoute</code> property to determine where the audio output is currently routed. This returns an <code>AVAudioSessionRouteDescription</code> object listing all of the audio session’s inputs and outputs. When a device is removed, you retrieve the <code>AVAudioSessionRouteDescription</code> object for the <em>previous</em> route from the <code>userInfo</code> dictionary. In both cases, you query the route description’s <code>outputs</code> property, which returns an array of <code>AVAudioSessionPortDescription</code> objects providing the details of the audio output routes.</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">func handleRouteChange(notification: NSNotification) {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    guard let userInfo = notification.userInfo,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let reasonValue = userInfo[AVAudioSessionRouteChangeReasonKey] as? UInt,</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let reason = AVAudioSessionRouteChangeReason(rawValue:reasonValue) else {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            return</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    switch reason {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    case .newDeviceAvailable:</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        let session = AVAudioSession.sharedInstance()</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        for output in session.currentRoute.outputs where output.portType == AVAudioSessionPortHeadphones {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            headphonesConnected = true</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    case .oldDeviceUnavailable:</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        if let previousRoute =</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            userInfo[AVAudioSessionRouteChangePreviousRouteKey] as? AVAudioSessionRouteDescription {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            for output in previousRoute.outputs where output.portType == AVAudioSessionPortHeadphones {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">                headphonesConnected = false</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">            }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    default: ()</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p><strong>Important:</strong> Media playback apps should pause playback if the route change reason is <code>AVAudioSessionRouteChangeReasonOldDeviceUnavailable</code>, but should not if the reason is <code>AVAudioSessionRouteChangeReasonOverride</code>.</p><p><strong>Note:</strong> An audio route change may also result in changes to the audio session’s sample rate, I/O buffer duration, channel counts, or other hardware-related values. If these values are important to your app, query them after a route change to see if their values have changed.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="configuring-device-hardware"></a>Configuring Device Hardware<a class="hash-link" href="#configuring-device-hardware" title="Direct link to heading">#</a></h2><p>Using audio session properties, you can optimize your app’s audio behavior for device hardware at runtime. Doing this lets your code adapt to the characteristics of the device it’s running on, as well as to changes made by the user (such as plugging in a headset or docking the device) as your app runs.</p><blockquote><p>Using audio session properties 使用audio session 属性</p><p>optimize： 优化</p></blockquote><p>Use <code>AVAudioSession</code> to:</p><ul><li>Specify your preferred hardware settings for sample rate and I/O buffer duration</li><li>Query many hardware characteristics, such as input and output latency, input and output channel count, hardware sample rate, hardware volume setting, and availability of audio input</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="choosing-preferred-audio-hardware-values"></a>Choosing Preferred Audio Hardware Values<a class="hash-link" href="#choosing-preferred-audio-hardware-values" title="Direct link to heading">#</a></h3><p>Use the audio session to specify your preferred device settings, such as sample rate and hardware I/O buffer duration. Table 5-1 describes the benefits and costs of these preferences.</p><p><img alt="image-20210124171039521" src="/assets/images/image-20210124171039521-753c2ea6e79ddeb2d17e8198790c9c02.png"></p><p>For example, you might specify a preference for a high sample rate if audio quality is very important in your app, and if large file or buffer size is not a significant issue.</p><p><strong>Note:</strong> The default audio I/O buffer duration (about 0.02 seconds for 44.1 kHz audio) provides sufficient responsiveness for most apps. You can set a lower I/O duration for latency-critical apps such as live musical instrument monitoring, but you’ll never need to modify this setting for most apps.</p><blockquote><p>latency-critical apps. 低延迟的关键应用</p><p>is not a significant issue. 不是一个大问题</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="setting-preferred-audio-hardware-values"></a>Setting Preferred Audio Hardware Values<a class="hash-link" href="#setting-preferred-audio-hardware-values" title="Direct link to heading">#</a></h3><p>Set preferred hardware values before you activate your audio session. If you&#x27;re already running an audio session, deactivate it. Changes to preferred values take effect after the audio session is activated, and you can verify the changes at that time. Listing 5-1 shows how to set preferred hardware values and how to verify them.</p><p><strong>Listing 5-1</strong> Setting and verifying audio hardware values</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">let session = AVAudioSession.sharedInstance()</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Configure category and mode</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">do {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try session.setCategory(AVAudioSessionCategoryRecord, mode: AVAudioSessionModeDefault)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">} catch let error as NSError {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Unable to set category:  \(error.localizedDescription)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Set preferred sample rate</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">do {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try session.setPreferredSampleRate(44_100)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">} catch let error as NSError {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Unable to set preferred sample rate:  \(error.localizedDescription)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Set preferred I/O buffer duration</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">do {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try session.setPreferredIOBufferDuration(0.005)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">} catch let error as NSError {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Unable to set preferred I/O buffer duration:  \(error.localizedDescription)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Activate the audio session</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">do {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try session.setActive(true)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">} catch let error as NSError {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Unable to activate session. \(error.localizedDescription)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Query the audio session&#x27;s ioBufferDuration and sampleRate properties</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// to determine if the preferred values were set</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">print(&quot;Audio Session ioBufferDuration: \(session.ioBufferDuration), sampleRate: \(session.sampleRate)&quot;)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><blockquote><p>to determine if the preferred values were set 去决定是否设置了首选值</p></blockquote><p>Note: When competing audio sessions set preferred hardware values, the system gives priority to nonmixable sessions. An audio session using the AVAudioSessionCategoryAmbient category or the AVAudioSessionCategoryOptionMixWithOthers option is unlikely to have its preferred hardware settings honored.</p><blockquote><p>the system gives priority to nonmixable session 系统会给不混合的会话优先级</p></blockquote><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="selecting-and-configuring-microphones"></a>Selecting And Configuring Microphones<a class="hash-link" href="#selecting-and-configuring-microphones" title="Direct link to heading">#</a></h3><p>On devices with two or more built-in microphones, iOS automatically selects a microphone through the use of audio session modes. A mode specifies the digital signal processing (DSP) used for input, and the possible routes. The input and routes are optimized for each mode&#x27;s use case. Setting a mode may also affect other aspects of the route being used.</p><p>Developers can also manually select microphones and even select a preferred microphone polar pattern if the hardware supports it.</p><blockquote><p>through the use of audio session modes.  通过使用的session modes。</p></blockquote><p><strong>Important:</strong> Before using any of the input selection features, set the audio session category and mode for your app, and then activate the audio session.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="setting-a-preferred-input"></a>Setting a Preferred Input<a class="hash-link" href="#setting-a-preferred-input" title="Direct link to heading">#</a></h4><p>To discover built-in or connected input ports, use the audio session’s <code>availableInputs</code> property. This property returns an array of <code>AVAudioSessionPortDescription</code> objects that describe the device’s available input ports. Ports can be identified by their <code>portType</code> property. To set a preferred input port (built-in microphone, wired microphone, USB input, and so on) use the audio session’s <code>setPreferredInput:error:</code> method.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="setting-a-preferred-datasource"></a>Setting a Preferred DataSource<a class="hash-link" href="#setting-a-preferred-datasource" title="Direct link to heading">#</a></h4><p>Some ports, such as the built-in microphone and some USB accessories, support data sources. Apps can discover available data sources by querying the port description’s <code>dataSources</code> property. In the case of the built-in microphone, the returned data source description objects represent each individual microphone. Different devices return different values for the built-in mic. For instance, the iPhone 4 and iPhone 4S have two microphones: bottom and top. The iPhone 5 has three microphones: bottom, front, and back.</p><p>Individual built-in microphones may be identified by a combination of a data source description’s <code>location</code> property (upper, lower) and <code>orientation</code> property (front, back, and so on). Apps may set a preferred data source by using the <code>setPreferredDataSource:error:</code> method of an <code>AVAudioSessionPortDescription</code> object.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="setting-a-preferred-polar-pattern"></a>Setting a Preferred Polar Pattern<a class="hash-link" href="#setting-a-preferred-polar-pattern" title="Direct link to heading">#</a></h4><p>Some iOS devices support configuring microphone polar patterns for some of the built-in microphones. A microphone’s polar pattern defines its sensitivity to sound relative to the direction of the sound source. Current-generation iPhones support setting the preferred polar pattern for the front and back built-in microphones. Available patterns are returned using the <code>supportedPolarPatterns</code> property of a data source description object. This property returns either an array of supported polar patterns for the data source, such as cardioid or omnidirectional, or <code>nil</code> when no selectable patterns are available. If the data source has a number of supported polar patterns, you can set the preferred polar pattern by using the data source description’s <code>setPreferredPolarPattern:error:</code> method.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="putting-it-all-together"></a>Putting it all Together<a class="hash-link" href="#putting-it-all-together" title="Direct link to heading">#</a></h4><p>The following code provides a simple example illustrating how to select a particular microphone and set its polar pattern.</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Preferred Mic = Front, Preferred Polar Pattern = Cardioid</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">let preferredMicOrientation = AVAudioSessionOrientationFront</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">let preferredPolarPattern = AVAudioSessionPolarPatternCardioid</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Retrieve your configured and activated audio session</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">let session = AVAudioSession.sharedInstance()</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Get available inputs</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">guard let inputs = session.availableInputs else { return }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Find built-in mic</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">guard let builtInMic = inputs.first(where: {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    $0.portType == AVAudioSessionPortBuiltInMic</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}) else { return }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Find the data source at the specified orientation</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">guard let dataSource = builtInMic.dataSources?.first (where: {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    $0.orientation == preferredMicOrientation</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}) else { return }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Set data source&#x27;s polar pattern</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">do {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try dataSource.setPreferredPolarPattern(preferredPolarPattern)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">} catch let error as NSError {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Unable to preferred polar pattern: \(error.localizedDescription)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Set the data source as the input&#x27;s preferred data source</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">do {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try builtInMic.setPreferredDataSource(dataSource)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">} catch let error as NSError {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Unable to preferred dataSource: \(error.localizedDescription)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Set the built-in mic as the preferred input</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// This call will be a no-op if already selected</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">do {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    try session.setPreferredInput(builtInMic)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">} catch let error as NSError {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Unable to preferred input: \(error.localizedDescription)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain"> </span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">// Print Active Configuration</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">session.currentRoute.inputs.forEach { portDesc in</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    print(&quot;Port: \(portDesc.portType)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    if let ds = portDesc.selectedDataSource {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        print(&quot;Name: \(ds.dataSourceName)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        print(&quot;Polar Pattern: \(ds.selectedPolarPattern ?? &quot;[none]&quot;)&quot;)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>Running this code on an iPhone 6s produces the following console output:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-undefined codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">Port: MicrophoneBuiltIn</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">Name: Front</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">Polar Pattern: Cardioid</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="runing-your-app-in-simulator"></a>Runing your app in simulator<a class="hash-link" href="#runing-your-app-in-simulator" title="Direct link to heading">#</a></h3><p>When you add audio session support to your app, you can run your app in Simulator or on a device. However, Simulator does not simulate most interactions between audio sessions in different processes or audio route changes. When running your app in Simulator, you cannot:</p><ul><li>Invoke an interruption</li><li>Simulate plugging in or unplugging a headset</li><li>Change the setting of the Silent switch</li><li>Simulate screen lock</li><li>Test audio mixing behavior—that is, playing your audio along with audio from another app (such as the Music app)</li></ul><blockquote><p> Simulator does not simulate most interactions between audio sessions in different processes or audio route changes.  模拟器不能模拟很多场景</p><p>Simulate plugging in or unplugging a headset 模拟插入，拔出耳机</p></blockquote><p>Because of the characteristics of Simulator, you may want to conditionalize your code to allow partial testing in Simulator. Listing 5-2 shows how to do this.</p><p><strong>Listing 5-2</strong> Using a conditional compilation block</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">#if arch(i386) || arch(x86_64)</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    // Execute subset of code that works in the Simulator</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">#else</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    // Execute device-only code as well as the other code</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">#endif</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><blockquote><p>conditionalize your code 条件化你的代码</p><p>allow partial testing in Simulator 允许在模拟器中部分设置</p><p>Using a conditional compilation block 使用条件编译块</p></blockquote><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="protecting-user-privacy"></a>Protecting User Privacy<a class="hash-link" href="#protecting-user-privacy" title="Direct link to heading">#</a></h2><p>To protect user privacy, your app must ask and receive permission from the user before recording audio. If the user does not grant permission, then only silence is recorded. The system automatically prompts the user for permission when you use a category that supports recording and the app attempts to use an input route.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="requesting-permission-to-record-audio"></a>Requesting Permission to Record Audio<a class="hash-link" href="#requesting-permission-to-record-audio" title="Direct link to heading">#</a></h3><p>Instead of waiting for the system to prompt the user for permission to record, you can use the <code>requestRecordPermission:</code> method to manually ask for permission. Using this method allows your app to get permission without interrupting the natural flow of the app, resulting in a better user experience.</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-swift codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#bfc7d5;background-color:#292d3e"><div class="token-line" style="color:#bfc7d5"><span class="token plain">AVAudioSession.sharedInstance().requestRecordPermission { granted in</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    if granted {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // User granted access. Present recording interface.</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    } else {</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // Present message to user indicating that recording</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // can&#x27;t be performed until they change their preference</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">        // under Settings -&gt; Privacy -&gt; Microphone</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">    }</span></div><div class="token-line" style="color:#bfc7d5"><span class="token plain">}</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p><strong>Important:</strong> As of iOS 10, all apps that access any of the device&#x27;s microphones must statically declare their intent to do so. To do this, apps must now include the <code>NSMicrophoneUsageDescription</code> key in their <code>Info.plist</code> file and provide a purpose string for this key. When the system prompts the user to allow access, this string is displayed as part of the alert.</p><p>If an app attempts to access any of the device&#x27;s microphones without this key and value present, the app will terminate.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="appendix-a-audio-guideline-by-app-type"></a>Appendix A: Audio Guideline By App Type<a class="hash-link" href="#appendix-a-audio-guideline-by-app-type" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-guidelines-for-game-apps"></a>Audio Guidelines for Game Apps<a class="hash-link" href="#audio-guidelines-for-game-apps" title="Direct link to heading">#</a></h3><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-guidelines-for-user-controlled-playback-and-recording-apps"></a>Audio Guidelines for User-Controlled Playback and Recording Apps<a class="hash-link" href="#audio-guidelines-for-user-controlled-playback-and-recording-apps" title="Direct link to heading">#</a></h3><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-guidelines-for-voip-and-chat-apps"></a>Audio Guidelines for VoIP and Chat Apps<a class="hash-link" href="#audio-guidelines-for-voip-and-chat-apps" title="Direct link to heading">#</a></h3><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-guidelines-for-metering-apps"></a>Audio Guidelines for Metering Apps<a class="hash-link" href="#audio-guidelines-for-metering-apps" title="Direct link to heading">#</a></h3><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-guidelines-for-browser-like-apps-that-sometimes-play-audio"></a>Audio Guidelines for Browser-like Apps That Sometimes Play Audio<a class="hash-link" href="#audio-guidelines-for-browser-like-apps-that-sometimes-play-audio" title="Direct link to heading">#</a></h3><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-guidelines-for-navigation-and-workout-apps"></a>Audio Guidelines for Navigation and Workout Apps<a class="hash-link" href="#audio-guidelines-for-navigation-and-workout-apps" title="Direct link to heading">#</a></h3><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="audio-guidelines-for-cooperative-music-apps"></a>Audio Guidelines for Cooperative Music Apps<a class="hash-link" href="#audio-guidelines-for-cooperative-music-apps" title="Direct link to heading">#</a></h3><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="appendix-b-audio-session-categories-and-modes"></a>Appendix B: Audio Session Categories and Modes<a class="hash-link" href="#appendix-b-audio-session-categories-and-modes" title="Direct link to heading">#</a></h2><p>You specify an audio session category to express how you intend to use audio in your app. Table B-1 provides details about each of the available categories. For an explanation of how categories work, see <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/AudioSessionBasics/AudioSessionBasics.html#//apple_ref/doc/uid/TP40007875-CH3-SW1" target="_blank" rel="noopener noreferrer">Configuring an Audio Session</a>.</p><p><img alt="image-20210124210614014" src="/assets/images/image-20210124210614014-dc566e2a74a6865d75344d12eebeabf1.png"></p><p><strong>Note:</strong> For your app to continue playing audio when the Ring/Silent switch is set to silent and the screen is locked, make sure the <code>UIBackgroundModes</code> <code>audio</code> key has been added to your app’s <code>Info.plist</code> file. This requirement is in addition to your using the correct category.</p><p>Table B-2 provides a list of modes and the categories each mode can be used with.</p><p>Table B-2  Modes and associated categories</p><p><img alt="image-20210124210657041" src="/assets/images/image-20210124210657041-303358266e6e532ebba85d43db88fb71.png"></p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="reference"></a>Reference<a class="hash-link" href="#reference" title="Direct link to heading">#</a></h2><ul><li>Apple document: <a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html" target="_blank" rel="noopener noreferrer">https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html</a></li></ul><p>Audio Session 参考：</p><ul><li><a href="https://developer.apple.com/library/archive/documentation/Audio/Conceptual/AudioSessionProgrammingGuide/Introduction/Introduction.html" target="_blank" rel="noopener noreferrer">Audio Session Programming Guide</a></li><li><a href="https://juejin.cn/post/6844903834385383431" target="_blank" rel="noopener noreferrer">Audio Session:系统与应用程序的中介</a> </li><li><a href="http://www.samirchen.com/ios-avaudiosession-3/" target="_blank" rel="noopener noreferrer">AVAudioSession(3)：定制 Audio Session 的 Category</a></li></ul><p><a href="https://stackoverflow.com/questions/15643516/list-available-output-audio-target-avaudiosession" target="_blank" rel="noopener noreferrer">https://stackoverflow.com/questions/15643516/list-available-output-audio-target-avaudiosession</a></p></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="dys-typora-open://mine/survival/docs/音视频/学习资料/教程/Audio-Session-Programming-Guide.md" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" role="img" viewBox="0 0 40 40" class="iconEdit_2LL7"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"></div><div class="pagination-nav__item pagination-nav__item--next"></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_2xL- thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#configuring--an-audio-session" class="table-of-contents__link">Configuring  an Audio Session</a><ul><li><a href="#audio-session-default-behavior" class="table-of-contents__link">Audio Session Default Behavior</a></li><li><a href="#configuring-your-audio-session" class="table-of-contents__link">Configuring Your Audio Session</a></li><li><a href="#expanding-options-using-the-multiroute-category" class="table-of-contents__link">Expanding Options Using the Multiroute Category</a></li><li><a href="#chooseing-categores-and-modes-for-airplay" class="table-of-contents__link">Chooseing Categores and Modes for Airplay</a></li><li><a href="#enabling-background-audio" class="table-of-contents__link">Enabling background Audio</a></li></ul></li><li><a href="#activating-an-audio-session" class="table-of-contents__link">Activating an Audio Session</a><ul><li><a href="#how-the-system-resolves-competing-audio-demands" class="table-of-contents__link">How the System Resolves Competing Audio Demands</a></li><li><a href="#activity-and-deactivaty-you-audio-session" class="table-of-contents__link">Activity and Deactivaty you Audio Session</a></li><li><a href="#checking-whether-other-audio-is-playing" class="table-of-contents__link">Checking Whether Other Audio is Playing</a></li></ul></li><li><a href="#responding-to-interruptions" class="table-of-contents__link">Responding to interruptions</a><ul><li><a href="#the-interruption-life-cycle" class="table-of-contents__link">The Interruption Life Cycle</a></li><li><a href="#audio-interruption-handling-techniques" class="table-of-contents__link">Audio Interruption handling Techniques</a></li><li><a href="#handling-interruption-from-siri" class="table-of-contents__link">Handling Interruption from Siri</a></li><li><a href="#observer-audio-interruptions" class="table-of-contents__link">Observer Audio Interruptions</a></li><li><a href="#responding--to-a-media-server-reset" class="table-of-contents__link">Responding  to a media server Reset</a></li></ul></li><li><a href="#responding-to-route-changes" class="table-of-contents__link">Responding to Route Changes</a><ul><li><a href="#varieties-of-audio-hardware-route-change" class="table-of-contents__link">Varieties Of Audio Hardware Route Change</a></li><li><a href="#observering-audio-route-changes" class="table-of-contents__link">Observering Audio Route Changes</a></li></ul></li><li><a href="#configuring-device-hardware" class="table-of-contents__link">Configuring Device Hardware</a><ul><li><a href="#choosing-preferred-audio-hardware-values" class="table-of-contents__link">Choosing Preferred Audio Hardware Values</a></li><li><a href="#setting-preferred-audio-hardware-values" class="table-of-contents__link">Setting Preferred Audio Hardware Values</a></li><li><a href="#selecting-and-configuring-microphones" class="table-of-contents__link">Selecting And Configuring Microphones</a></li><li><a href="#runing-your-app-in-simulator" class="table-of-contents__link">Runing your app in simulator</a></li></ul></li><li><a href="#protecting-user-privacy" class="table-of-contents__link">Protecting User Privacy</a><ul><li><a href="#requesting-permission-to-record-audio" class="table-of-contents__link">Requesting Permission to Record Audio</a></li></ul></li><li><a href="#appendix-a-audio-guideline-by-app-type" class="table-of-contents__link">Appendix A: Audio Guideline By App Type</a><ul><li><a href="#audio-guidelines-for-game-apps" class="table-of-contents__link">Audio Guidelines for Game Apps</a></li><li><a href="#audio-guidelines-for-user-controlled-playback-and-recording-apps" class="table-of-contents__link">Audio Guidelines for User-Controlled Playback and Recording Apps</a></li><li><a href="#audio-guidelines-for-voip-and-chat-apps" class="table-of-contents__link">Audio Guidelines for VoIP and Chat Apps</a></li><li><a href="#audio-guidelines-for-metering-apps" class="table-of-contents__link">Audio Guidelines for Metering Apps</a></li><li><a href="#audio-guidelines-for-browser-like-apps-that-sometimes-play-audio" class="table-of-contents__link">Audio Guidelines for Browser-like Apps That Sometimes Play Audio</a></li><li><a href="#audio-guidelines-for-navigation-and-workout-apps" class="table-of-contents__link">Audio Guidelines for Navigation and Workout Apps</a></li><li><a href="#audio-guidelines-for-cooperative-music-apps" class="table-of-contents__link">Audio Guidelines for Cooperative Music Apps</a></li></ul></li><li><a href="#appendix-b-audio-session-categories-and-modes" class="table-of-contents__link">Appendix B: Audio Session Categories and Modes</a></li><li><a href="#reference" class="table-of-contents__link">Reference</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Docs</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/">Style Guide</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/">Second Doc</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Community</h4><ul class="footer__items"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow</a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://twitter.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">More</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/facebook/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2021 My Project, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/styles.9888532b.js"></script>
<script src="/runtime~main.73fb2e0e.js"></script>
<script src="/main.a2e30791.js"></script>
<script src="/1.fa235d9f.js"></script>
<script src="/2.8423217f.js"></script>
<script src="/257.8905f2ed.js"></script>
<script src="/258.3860215e.js"></script>
<script src="/935f2afb.ce536a1e.js"></script>
<script src="/17896441.d8a5f7af.js"></script>
<script src="/2bccc580.d3084068.js"></script>
</body>
</html>